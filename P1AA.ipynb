{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/100495802/G11.AA-495802-495702/blob/main/P1AA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# P1-AA: PREDICCIÓN DEL ABANDONO DE EMPLEADOS DE UNA EMPRESA\n",
        "- Curso de Aprendizaje Automático 2024/25\n",
        "- Grado en Ingeniería Informática - UC3M\n",
        "- Alejandro López Sancho: 100495702\n",
        "- Javier Rosales Lozano: 100495802"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Introducción y carga de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1. Enunciado del proyecto\n",
        "\n",
        "El siguiente notebook contiene toda la información y trabajo realizado acerca de la primera parte de la práctica inicial del curso de Aprendizaje Automático 2024/25. El objetivo de esta práctica es realizar la __construcción, medición y evaluación de un modelo que prediga un problema planteado como el número de abandonos dentro de una empresa en función de las características de sus trabajadores__.\n",
        "\n",
        "En este primer archivo de Jupyter Notebook encontraremos todo el proceso de EDA (Exploratory Data Analysis), selección de imputers y scalers, ajuste de hiperparámetros, evaluación de modelos, obtención de la tasa de aprendizaje y resolución de las preguntas establecidas en el enunciado de la práctica."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.2. Repositorio Github y Dataset Inicial\n",
        "\n",
        "El siguiente enlace redirige al [repositorio Github](https://github.com/100495802/G11.AA-495802-495702.git) correspondiente al proyecto; los datos elegidos para la realización del proyecto corresponden con el estándar especificado para la realización del trabajo (suma de los dos últimos dígitos de uno de los NIAs del grupo de prácticas). En este caso, hemos elegido el NIA __100495702__, por lo que nuestro [dataset inicial](attrition_availabledata_02.csv.gz) corresponderá con el número _2_ del conjunto de datasets del Aula Global."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkvWftzzAVYR"
      },
      "source": [
        "### 1.3. Carga de Datos\n",
        "\n",
        "A continuación, nos disponemos a la __carga de este conjunto de datos__:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "SWvqYujY3lYu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "datos = pd.read_csv(\"attrition_availabledata_02.csv.gz\", compression=\"gzip\", sep=\",\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LYoIph_A4hU"
      },
      "source": [
        "# 2. EDA Simplificado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Una vez cargado el dataset, nos disponemos a comentar y describir los distintos datos que existen en el dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43xv2WeM6CnM"
      },
      "source": [
        "### 2.1. Análisis general del dataset\n",
        "\n",
        "Vamos a investigar primeramente el tamaño del dataset; esto lo haremos con los atributos de la librería Pandas _.shape_ y _.size_. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tamaño del dataset: (2940, 31)\n",
            "Número total de elementos del dataset: 91140\n"
          ]
        }
      ],
      "source": [
        "print(f\"Tamaño del dataset: {datos.shape}\")\n",
        "print(f\"Número total de elementos del dataset: {datos.size}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Podemos observar que el tamaño del dataset es de __2940 filas (instancias) y 31 columnas (atributos)__. También identificamos el número de elementos del conjunto de datos.\n",
        "\n",
        "Seguidamente, echaremos un vistazo rápido a los atributos que hay en la base de datos; usaremos el método _info()_ para identificar las diferentes columnas del dataset, además del tipo de dato y el número de instancias no nulas que contiene."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGsKcVKh78gf",
        "outputId": "567a33d3-b192-470e-f5c7-16ff4d54c54e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2940 entries, 0 to 2939\n",
            "Data columns (total 31 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   hrs                      2940 non-null   float64\n",
            " 1   absences                 2940 non-null   int64  \n",
            " 2   JobInvolvement           2940 non-null   int64  \n",
            " 3   PerformanceRating        2940 non-null   int64  \n",
            " 4   EnvironmentSatisfaction  2927 non-null   float64\n",
            " 5   JobSatisfaction          2925 non-null   float64\n",
            " 6   WorkLifeBalance          2911 non-null   float64\n",
            " 7   Age                      2940 non-null   int64  \n",
            " 8   BusinessTravel           2940 non-null   object \n",
            " 9   Department               2940 non-null   object \n",
            " 10  DistanceFromHome         2940 non-null   int64  \n",
            " 11  Education                2940 non-null   int64  \n",
            " 12  EducationField           2940 non-null   object \n",
            " 13  EmployeeCount            2940 non-null   int64  \n",
            " 14  EmployeeID               2940 non-null   int64  \n",
            " 15  Gender                   2940 non-null   object \n",
            " 16  JobLevel                 2940 non-null   int64  \n",
            " 17  JobRole                  2940 non-null   object \n",
            " 18  MaritalStatus            2940 non-null   object \n",
            " 19  MonthlyIncome            2940 non-null   int64  \n",
            " 20  NumCompaniesWorked       2926 non-null   float64\n",
            " 21  Over18                   2940 non-null   object \n",
            " 22  PercentSalaryHike        2940 non-null   int64  \n",
            " 23  StandardHours            2940 non-null   int64  \n",
            " 24  StockOptionLevel         2940 non-null   int64  \n",
            " 25  TotalWorkingYears        2935 non-null   float64\n",
            " 26  TrainingTimesLastYear    2940 non-null   int64  \n",
            " 27  YearsAtCompany           2940 non-null   int64  \n",
            " 28  YearsSinceLastPromotion  2940 non-null   int64  \n",
            " 29  YearsWithCurrManager     2940 non-null   int64  \n",
            " 30  Attrition                2940 non-null   object \n",
            "dtypes: float64(6), int64(17), object(8)\n",
            "memory usage: 712.2+ KB\n"
          ]
        }
      ],
      "source": [
        "datos.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "En la salida podemos observar una tabla donde apreciamos el nombre del atirbuto, el número de instancias no vacías y el tipo de dato de ésta columna. Esto nos servirá para apreciar los tipos de datos que estamos analizando.\n",
        "\n",
        "Podemos observar que algunos de ellos cumplen con todas sus filas con algún valor no nulo (N/A), mientras que __otras columnas no alcanzan el número total de filas obtenido anteriormente (2940)__.\n",
        "\n",
        "Por otro lado, el tipo de datos nos hace preveer cuáles columnas representan __atributos categóricos__ (_object_) y cuáles __atributos numéricos__ (_int64, float64_).\n",
        "\n",
        "Para un resumen más detallado, nos serviremos de otro método de Pandas: _.describe()_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "bj5Iv-POWqDw",
        "outputId": "02f60f31-0b0c-4ebe-cde1-0fb0360bee09"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hrs</th>\n",
              "      <th>absences</th>\n",
              "      <th>JobInvolvement</th>\n",
              "      <th>PerformanceRating</th>\n",
              "      <th>EnvironmentSatisfaction</th>\n",
              "      <th>JobSatisfaction</th>\n",
              "      <th>WorkLifeBalance</th>\n",
              "      <th>Age</th>\n",
              "      <th>DistanceFromHome</th>\n",
              "      <th>Education</th>\n",
              "      <th>...</th>\n",
              "      <th>MonthlyIncome</th>\n",
              "      <th>NumCompaniesWorked</th>\n",
              "      <th>PercentSalaryHike</th>\n",
              "      <th>StandardHours</th>\n",
              "      <th>StockOptionLevel</th>\n",
              "      <th>TotalWorkingYears</th>\n",
              "      <th>TrainingTimesLastYear</th>\n",
              "      <th>YearsAtCompany</th>\n",
              "      <th>YearsSinceLastPromotion</th>\n",
              "      <th>YearsWithCurrManager</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2940.000000</td>\n",
              "      <td>2940.000000</td>\n",
              "      <td>2940.000000</td>\n",
              "      <td>2940.000000</td>\n",
              "      <td>2927.000000</td>\n",
              "      <td>2925.000000</td>\n",
              "      <td>2911.000000</td>\n",
              "      <td>2940.000000</td>\n",
              "      <td>2940.000000</td>\n",
              "      <td>2940.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>2940.000000</td>\n",
              "      <td>2926.000000</td>\n",
              "      <td>2940.000000</td>\n",
              "      <td>2940.0</td>\n",
              "      <td>2940.000000</td>\n",
              "      <td>2935.000000</td>\n",
              "      <td>2940.000000</td>\n",
              "      <td>2940.000000</td>\n",
              "      <td>2940.000000</td>\n",
              "      <td>2940.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>7.322768</td>\n",
              "      <td>12.706803</td>\n",
              "      <td>2.728571</td>\n",
              "      <td>3.154422</td>\n",
              "      <td>2.723266</td>\n",
              "      <td>2.746325</td>\n",
              "      <td>2.760907</td>\n",
              "      <td>36.861224</td>\n",
              "      <td>9.305102</td>\n",
              "      <td>2.906463</td>\n",
              "      <td>...</td>\n",
              "      <td>64379.826531</td>\n",
              "      <td>2.664388</td>\n",
              "      <td>15.187075</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.785034</td>\n",
              "      <td>11.363884</td>\n",
              "      <td>2.798639</td>\n",
              "      <td>7.095578</td>\n",
              "      <td>2.227891</td>\n",
              "      <td>4.191156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.335600</td>\n",
              "      <td>5.533199</td>\n",
              "      <td>0.716167</td>\n",
              "      <td>0.361414</td>\n",
              "      <td>1.096170</td>\n",
              "      <td>1.104612</td>\n",
              "      <td>0.713539</td>\n",
              "      <td>9.286733</td>\n",
              "      <td>8.201638</td>\n",
              "      <td>1.023254</td>\n",
              "      <td>...</td>\n",
              "      <td>47021.197990</td>\n",
              "      <td>2.495153</td>\n",
              "      <td>3.661275</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.851343</td>\n",
              "      <td>7.897032</td>\n",
              "      <td>1.304166</td>\n",
              "      <td>6.161878</td>\n",
              "      <td>3.274101</td>\n",
              "      <td>3.627734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>5.416880</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>10090.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>6.272786</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>28750.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>7.032627</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>48340.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>7.948416</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>80080.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>7.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>10.937261</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>199990.000000</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>8.0</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>17.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               hrs     absences  JobInvolvement  PerformanceRating  \\\n",
              "count  2940.000000  2940.000000     2940.000000        2940.000000   \n",
              "mean      7.322768    12.706803        2.728571           3.154422   \n",
              "std       1.335600     5.533199        0.716167           0.361414   \n",
              "min       5.416880     1.000000        1.000000           3.000000   \n",
              "25%       6.272786     8.000000        2.000000           3.000000   \n",
              "50%       7.032627    13.000000        3.000000           3.000000   \n",
              "75%       7.948416    17.000000        3.000000           3.000000   \n",
              "max      10.937261    24.000000        4.000000           4.000000   \n",
              "\n",
              "       EnvironmentSatisfaction  JobSatisfaction  WorkLifeBalance          Age  \\\n",
              "count              2927.000000      2925.000000      2911.000000  2940.000000   \n",
              "mean                  2.723266         2.746325         2.760907    36.861224   \n",
              "std                   1.096170         1.104612         0.713539     9.286733   \n",
              "min                   1.000000         1.000000         1.000000    18.000000   \n",
              "25%                   2.000000         2.000000         2.000000    30.000000   \n",
              "50%                   3.000000         3.000000         3.000000    35.000000   \n",
              "75%                   4.000000         4.000000         3.000000    43.000000   \n",
              "max                   4.000000         4.000000         4.000000    60.000000   \n",
              "\n",
              "       DistanceFromHome    Education  ...  MonthlyIncome  NumCompaniesWorked  \\\n",
              "count       2940.000000  2940.000000  ...    2940.000000         2926.000000   \n",
              "mean           9.305102     2.906463  ...   64379.826531            2.664388   \n",
              "std            8.201638     1.023254  ...   47021.197990            2.495153   \n",
              "min            1.000000     1.000000  ...   10090.000000            0.000000   \n",
              "25%            2.000000     2.000000  ...   28750.000000            1.000000   \n",
              "50%            7.000000     3.000000  ...   48340.000000            2.000000   \n",
              "75%           14.000000     4.000000  ...   80080.000000            4.000000   \n",
              "max           29.000000     5.000000  ...  199990.000000            9.000000   \n",
              "\n",
              "       PercentSalaryHike  StandardHours  StockOptionLevel  TotalWorkingYears  \\\n",
              "count        2940.000000         2940.0       2940.000000        2935.000000   \n",
              "mean           15.187075            8.0          0.785034          11.363884   \n",
              "std             3.661275            0.0          0.851343           7.897032   \n",
              "min            11.000000            8.0          0.000000           0.000000   \n",
              "25%            12.000000            8.0          0.000000           6.000000   \n",
              "50%            14.000000            8.0          1.000000          10.000000   \n",
              "75%            18.000000            8.0          1.000000          16.000000   \n",
              "max            25.000000            8.0          3.000000          40.000000   \n",
              "\n",
              "       TrainingTimesLastYear  YearsAtCompany  YearsSinceLastPromotion  \\\n",
              "count            2940.000000     2940.000000              2940.000000   \n",
              "mean                2.798639        7.095578                 2.227891   \n",
              "std                 1.304166        6.161878                 3.274101   \n",
              "min                 0.000000        0.000000                 0.000000   \n",
              "25%                 2.000000        3.000000                 0.000000   \n",
              "50%                 3.000000        5.000000                 1.000000   \n",
              "75%                 3.000000       10.000000                 3.000000   \n",
              "max                 6.000000       40.000000                15.000000   \n",
              "\n",
              "       YearsWithCurrManager  \n",
              "count           2940.000000  \n",
              "mean               4.191156  \n",
              "std                3.627734  \n",
              "min                0.000000  \n",
              "25%                2.000000  \n",
              "50%                3.000000  \n",
              "75%                7.000000  \n",
              "max               17.000000  \n",
              "\n",
              "[8 rows x 23 columns]"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "datos.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ésta ejecución de código nos permite identificar algunas __métricas estadísticas__ acerca del conjunto de datos que abarcan los distintos atributos (como la media, la mediana, mínimos, máximos y rangos intercuartílicos). Esto de momento no nos servirá, pero quizás más adelante será útil.\n",
        "\n",
        "Con los datos visualizados anteriormente en la ejecución de _.info()_, vamos a observar los valores de las variables más a fondo, haciendo hincapié en las distintas observaciones que se piden en la práctica."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2. Variables numéricas y categóricas; variables con alta cardinalidad\n",
        "\n",
        "Empezamos distinguiendo los atributos que representan __valores categóricos__ de los que representan __valores numéricos__ (descartando la columna de la variable de salida, _Attrition_, la cual sabemos que es categórica):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNnSTQQQbP0p",
        "outputId": "2abcdfee-91e1-4a09-ebaa-7ad68133b8d6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['hrs', 'absences', 'JobInvolvement', 'PerformanceRating',\n",
            "       'EnvironmentSatisfaction', 'JobSatisfaction', 'WorkLifeBalance', 'Age',\n",
            "       'DistanceFromHome', 'Education', 'EmployeeCount', 'EmployeeID',\n",
            "       'JobLevel', 'MonthlyIncome', 'NumCompaniesWorked', 'PercentSalaryHike',\n",
            "       'StandardHours', 'StockOptionLevel', 'TotalWorkingYears',\n",
            "       'TrainingTimesLastYear', 'YearsAtCompany', 'YearsSinceLastPromotion',\n",
            "       'YearsWithCurrManager'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "numericas = datos.select_dtypes(include=['int64', 'float64']).columns\n",
        "print(numericas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEdrwVfGGsWx",
        "outputId": "70cadd60-eabb-45af-8e66-609cdc360f1c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['BusinessTravel', 'Department', 'EducationField', 'Gender', 'JobRole',\n",
            "       'MaritalStatus', 'Over18'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "categoricas = datos.select_dtypes(include=[\"object\"]).columns.drop(\"Attrition\")\n",
        "print(categoricas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrB0wuSW6dzQ"
      },
      "source": [
        "A continuación, de las __variables categóricas__, vamos a identificar aquellas variables con una __alta cardinalidad__ en sus valores:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBkwR4EyZAf3",
        "outputId": "0ba21f4d-1d2b-4d63-c871-8ac6e92fc142"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BusinessTravel\n",
            "['Travel_Frequently' 'Non-Travel' 'Travel_Rarely']\n",
            "Department\n",
            "['Research & Development' 'Sales' 'Human Resources']\n",
            "EducationField\n",
            "['Life Sciences' 'Medical' 'Other' 'Technical Degree' 'Marketing'\n",
            " 'Human Resources']\n",
            "Gender\n",
            "['Male' 'Female']\n",
            "JobRole\n",
            "['Laboratory Technician' 'Healthcare Representative' 'Research Scientist'\n",
            " 'Sales Representative' 'Manufacturing Director' 'Sales Executive'\n",
            " 'Research Director' 'Human Resources' 'Manager']\n",
            "MaritalStatus\n",
            "['Married' 'Divorced' 'Single']\n",
            "Over18\n",
            "['Y']\n",
            "Attrition\n",
            "['Yes' 'No']\n"
          ]
        }
      ],
      "source": [
        "for columna in datos.select_dtypes(include=[\"object\"]).columns:\n",
        "    print(columna)\n",
        "    print(datos[columna].unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Analizando la salida de esta ejecución, podemos observar qué variables categóricas presentan elevada cardinalidad. __En este proyecto consideraremos con cardinalidad elevada un atributo con rango de posibles opciones mayor de 4__.\n",
        "\n",
        "En este caso, las columnas con alta cardinalidad son _EducationField_ y _JobRole_."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnAB60GjZXKI"
      },
      "source": [
        "### 2.3. Variables nulas\n",
        "\n",
        "Para el preprocesado de datos, es importante determinar qué instancias contienen __valores nulos__, y el número de instancias de este tipo en cada columna. Esto lo comprobamos con el método de Pandas _.isnull()_:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "lJo1LEBiHUn8",
        "outputId": "5962962c-b074-49f5-f297-bef49573d2bf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "EnvironmentSatisfaction    13\n",
              "JobSatisfaction            15\n",
              "WorkLifeBalance            29\n",
              "NumCompaniesWorked         14\n",
              "TotalWorkingYears           5\n",
              "dtype: int64"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nulos = datos.isnull().sum()\n",
        "nulos[nulos > 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMO0HTDiXN0t"
      },
      "source": [
        "Como podemos observar, en el dataset se aprecian __cinco columnas con valores nulos__ en sus filas: _EnvironmentSatisfaction, JobSatisfaction, WorkLifeBalance, NumCompaniesWorked, TotalWorkingYears_. Teniendo en cuenta que en total hay 2940 filas en la base de datos, se pueden calcular fácilmente la media de datos vacíos por columna.\n",
        "\n",
        "Si recordamos de qué tipo era cada variable, podemos observar que __todas estas columnas corresponden con variables numéricas__, y podemos ir pensando ya en posibilidades para trabajar con estos valores vacíos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.4. Variables de identificación (ID)\n",
        "\n",
        "Una vez analizado todo lo anterior, empezamos a buscar qué posibles columnas actúan como identificadores en la base de datos. A simple vista, una posible opción sería _EmployeeID_, aunque es mejor comprobarlo con la llamada al método _.nunique()_:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLbSgDVZcUId",
        "outputId": "6514bd9d-b61b-4dd5-ec4e-18ea7811898f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "La columna 'EmployeeID' es un posible identificador único.\n"
          ]
        }
      ],
      "source": [
        "for columna in datos.columns:\n",
        "    if datos[columna].nunique() == len(datos):\n",
        "        print(f\"La columna '{columna}' es un posible identificador único.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "\"['EmployeeNumber'] not found in axis\"",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[65], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdatos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEmployeeNumber\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\JAVIER\\PycharmProjects\\AA.2024-25\\.venv\\lib\\site-packages\\pandas\\core\\frame.py:5581\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   5433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mdrop\u001b[39m(\n\u001b[0;32m   5434\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   5435\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5442\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   5443\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5444\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   5445\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[0;32m   5446\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5579\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[0;32m   5580\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 5581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5583\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5587\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5588\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\JAVIER\\PycharmProjects\\AA.2024-25\\.venv\\lib\\site-packages\\pandas\\core\\generic.py:4788\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[1;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[0;32m   4786\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m   4787\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 4788\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[0;32m   4791\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
            "File \u001b[1;32mc:\\Users\\JAVIER\\PycharmProjects\\AA.2024-25\\.venv\\lib\\site-packages\\pandas\\core\\generic.py:4830\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[1;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[0;32m   4828\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m   4829\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4830\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4831\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[0;32m   4833\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[0;32m   4834\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "File \u001b[1;32mc:\\Users\\JAVIER\\PycharmProjects\\AA.2024-25\\.venv\\lib\\site-packages\\pandas\\core\\indexes\\base.py:7070\u001b[0m, in \u001b[0;36mIndex.drop\u001b[1;34m(self, labels, errors)\u001b[0m\n\u001b[0;32m   7068\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[0;32m   7069\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 7070\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   7071\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[0;32m   7072\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
            "\u001b[1;31mKeyError\u001b[0m: \"['EmployeeNumber'] not found in axis\""
          ]
        }
      ],
      "source": [
        "datos.drop(\"EmployeeNumber\", axis=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nuestras sospechas han resultado ser ciertas, y es que es el único atributo cuyos valores son únicos, y no coinciden dos o más instancias con el mismo valor en esta columna. Más adelante decidiremos qué hacer con esta columna."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.5. ¿Problema desbalanceado?\n",
        "\n",
        "Con el planteamiento completo del enunciado se puede intuir que estamos ante un __problema de clasificación__. Además, la variable _Attrition_ es la que determinará si un empleado es propenso a abandonar la empresa en función del resto de columnas.\n",
        "\n",
        "Sin embargo, todavía __no podemos comprobar si se trata de un problema de clasificación desbalanceado__, ya que no hemos hecho un conteo de los valores de dicha columna. Este paso es importante, ya que marcará la manera en la que realizaremos las particiones para entrenar, validar y evaluar el modelo.\n",
        "\n",
        "Para averiguarlo, usaremos el método _.value_counts()_:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "_Q-zUraNevYv",
        "outputId": "0033e00c-768d-4feb-9f1a-c44b1fb56024"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Attrition\n",
              "No     2466\n",
              "Yes     474\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "datos[\"Attrition\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "La salida de la ejecución nos muestra el conteo de datos de dicha columna, lo que demuestra que __se trata de un problema desbalanceado__ hacia el valor \"no\", siendo más del 80% de las clasificaciones de este tipo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Metodología de trabajo: Decidir cómo se va a realizar la evaluación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTaYmNfae8R8"
      },
      "source": [
        "Una vez terminada la parte de análisis del conjunto de datos, podemos concluir en dos cosas:\n",
        "\n",
        "1. El problema es de clasificación, desbalanceado, con variables categóricas y numéricas, y algunas instancias contienen datos vacíos.\n",
        "\n",
        "2. Siendo el 80% de la muestra la que decide no abandonar, por el momento, la empresa puede estar tranquila.\n",
        "\n",
        "Con los datos ya analizados, procedemos a especificar la realización de la práctica. En este apartado vamos a comentar __cómo vamos a evaluar nuestro modelo__."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akCIMtyuDCPx"
      },
      "source": [
        "### 3.1. Planificación del entrenamiento\n",
        "\n",
        "- __División de los datos:__\n",
        "\n",
        "  Para realizar la evaluación de nuestro modelo, lo primero que tenemos que hacer es dividir el conjunto de datos en dos particiones de train y test. Usaremos __Holdout__ para invertir 2/3 de los datos para la parte de entrenamiento del modelo y el resto para evaluar el modelo final del entrenamiento.\n",
        "\n",
        "- __Preprocesado de datos:__\n",
        "\n",
        "  Para empezar con la fase de entrenamiento, primero deberemos ajustar unas métricas relacionadas con el dataset. Deberemos medir qué método de __imputación__ y __escalado__ de atributos genera un mejor rendimiento de los datos. Para esta medición, usaremos KNN con los hiperparámetros por defecto, y modificaremos el escalado usando varios formatos (_Standard, MinMax, Robust_) y también el tratado de datos vacios o imputación de datos, usando otras métricas (_Media, Mediana_, al tratarse de atributos numéricos). Por último, en todos los casos usaremos la metodología de evaluación de modelos __3-Fold con crossvalidation__. Con todo esto buscamos obtener el Escaler-Imputer que de el mejor rendimiento de la partición de entrenamiento.\n",
        "\n",
        "- __Creación de Modelos y Ajuste de hyperparametro HPO:__\n",
        "\n",
        "  Una vez hecho lo anterior, comenzamos la búsqueda del mejor modelo; se construirán una serie de modelos basandonos en las metodologías aprendidas en clase (KNN, Árboles de Decisión, Modelos Lineales y SVMs) mientras realizamos el __ajuste de hiperparámetros__ (HPO), y elegiremos el modelo que mejor se ajuste a los datos, procurando evitar cualquier data-leakage y overfitting/underfitting.\n",
        "\n",
        "- __Evaluación del modelo final de entrenamiento:__\n",
        "\n",
        "  Cuando hayamos encontrado la mejor alternativa usaremos el conjunto de test anteriormente apartado para obtener una __estimación y rendimiento a futuro del modelo__. Esto es lo que se conoce como la evaluación del modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2Zt93s-ERjL"
      },
      "source": [
        "### 3.2. Entrenamiento y evaluación del modelo final\n",
        "\n",
        "Los pasos anteriores en conjunto nos dirigen al entrenamiento del modelo final, el cual se entrena con el dataset completo (entrenamiento + test) y evaluaremos realizando predicciones con un conjunto de datos de competición aparte.\n",
        "\n",
        "Toda esta implementación se realiza en el [segundo Jupyter Notebook](enlacealsiguiente) a entregar con la práctica."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkRHkombEjzd"
      },
      "source": [
        "## 4. Métodos Básicos: KNN y TREES; imputación, escalado y ajuste de hiperparámetros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Como hemos establecido anteriormente, el primer paso es realizar el escalado/imputación de los datos, de manera que sea el modelo el que se ajuste a éstos. Para ello, es necesario la importación de las siguientes librerías de SkLearn:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "9nLBgZ27RFQP"
      },
      "outputs": [],
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.feature_selection import SelectPercentile, chi2\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from  sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, RobustScaler, StandardScaler\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1. División de los datos: particiones de entrenamiento y test\n",
        "\n",
        "Para establecer la división de los datos haremos uso de la función _train_test_split()_,  en la que especificaremos la metodología __Holdout__ que divide las particiones de entrenamiento y test en una proporción (2/3, 1/3).\n",
        "\n",
        "También inicializaremos el atributo _random_state_ con un valor predefinido, ya que esto garantiza que se mantenga el mismo conjunto de datos de partición de entrenamiento y de test en todas las ejecuciones. En el caso de inicializarlo a _None_, estaríamos dejando al azar el entrenamiento del modelo, ya que hay algunas métricas como en KNN que no se basan en estadísticas globales de los datos, y esto puede variar el resultado cada vez que ejecutemos el código.\n",
        "\n",
        "El valor elegido para _random_state_ será _42_ (número aleatorio).\n",
        "\n",
        "Una vez especificado esto, se procede a la partición de los datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "e0jHHodYKV6h"
      },
      "outputs": [],
      "source": [
        "X = datos.drop(\"Attrition\", axis=1)\n",
        "y = datos[\"Attrition\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tzbu8uVQRQn3"
      },
      "source": [
        "### 4.2. Escalado e imputación de la partición de entrenamiento.\n",
        "\n",
        "Una vez divididos los datos, buscaremos el modelo que mejor se adapte a la partición de entrenamiento según el tipo de imputación y escalado de datos. Para los escaladores usaremos los tres escaladores estudiados en clase para KNN: __MinMax (to 0-1 range), Estandarización y RobustScaler__; mientras que para los imputadores usaremos los especificados en el enunciado: __la media y la mediana__ de las variables de la misma instancia (imputación univariante).\n",
        "\n",
        "También usaremos como clasificador KNN y como métrica para la puntuación de cada imputer/scaler __balanced accuracy__:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jo8pt_MWFQuR",
        "outputId": "366d4e25-936a-427e-f924-7e90e05e94fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scaler: StandardScaler(), Imputer: SimpleImputer(), Score: 0.5761237407807159\n",
            "Scaler: StandardScaler(), Imputer: SimpleImputer(strategy='median'), Score: 0.5764301133297356\n",
            "Scaler: MinMaxScaler(), Imputer: SimpleImputer(), Score: 0.573666014570966\n",
            "Scaler: MinMaxScaler(), Imputer: SimpleImputer(strategy='median'), Score: 0.573666014570966\n",
            "Scaler: RobustScaler(), Imputer: SimpleImputer(), Score: 0.5883600917431192\n",
            "Scaler: RobustScaler(), Imputer: SimpleImputer(strategy='median'), Score: 0.5834665632307968\n",
            "\n",
            "Mejor Scaler: RobustScaler(), Mejor Imputer: SimpleImputer(), Mejor Score: 0.5883600917431192\n"
          ]
        }
      ],
      "source": [
        "# Lista de escaladores e imputadores\n",
        "Scalers = [StandardScaler(), MinMaxScaler(), RobustScaler()]\n",
        "Imputers = [SimpleImputer(strategy=\"mean\"), SimpleImputer(strategy=\"median\")]\n",
        "\n",
        "# Variables para almacenar el mejor modelo y su puntuación\n",
        "mejor_scaler = None\n",
        "mejor_imputer = None\n",
        "mejor_score = 0\n",
        "\n",
        "# Defiinimos el transformer para columnas categóricas\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "  (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "  ])\n",
        "\n",
        "# Iteramos sobre los escaladores\n",
        "for scaler in Scalers:\n",
        "\n",
        "  # Iteramos sobre los imputadores\n",
        "  for imputer in Imputers:\n",
        "\n",
        "    # Pipeline para las columnas numéricas\n",
        "    numerical_transformer = Pipeline(steps=[\n",
        "      (\"imputer\", imputer), (\"scaler\", scaler)\n",
        "      ])\n",
        "    \n",
        "    # Preprocesador combinado\n",
        "    preprocessor = ColumnTransformer(transformers=[\n",
        "      (\"num\", numerical_transformer, numericas), \n",
        "      (\"cat\", categorical_transformer, categoricas)\n",
        "      ])\n",
        "    \n",
        "    # Pipeline completo con clasificador (se utiliza KNN para clasificar)\n",
        "    pipeline = Pipeline(steps=[\n",
        "      (\"preprocessor\", preprocessor), \n",
        "      (\"classifier\", KNeighborsClassifier())\n",
        "      ])\n",
        "    \n",
        "    # Evaluación del modelo con 3-fold cross-validation (se utiliza balanced_accuracy como métrica)\n",
        "    score = cross_val_score(pipeline, X_train, y_train, \n",
        "                            cv=3, scoring=\"balanced_accuracy\").mean()\n",
        "    \n",
        "    # Comparamos con el mejor modelo\n",
        "    if score > mejor_score:\n",
        "      mejor_score = score\n",
        "      mejor_scaler = scaler\n",
        "      mejor_imputer = imputer\n",
        "    \n",
        "    # Imprimimos los resultados de cada combinación\n",
        "    print(f\"Scaler: {scaler}, Imputer: {imputer}, Score: {score}\")\n",
        "\n",
        "# Obtenemos el mejor scaler/imputer y su score\n",
        "print(f\"\\nMejor Scaler: {mejor_scaler}, Mejor Imputer: {mejor_imputer}, Mejor Score: {mejor_score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvPTlpAsQhw9"
      },
      "source": [
        "Observando los datos podemos concluir que el mejor método de escalado es __RobustScaler()__, el cual es particularmente útil cuando existen valores atípicos en los datos, ya que transforma los atributos usando la mediana y el rango intercuartílico; mientras que el mejor método de imputación (univariante) es __SimpleImputer(strategy=\"mean\")__, el cual reemplaza los valores faltantes con la media de cada atributo. Esta estrategia es muy común y sobretodo adecuada cuando los datos son aproximadamente simétricos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VNkG3zPARJ7Q"
      },
      "source": [
        "### 4.3. Modelos iniciales con hiperparámetros por defecto\n",
        "\n",
        "Una vez tenemos los métodos de escalado y de imputación seleccionados podemos pasar a la siguiente fase. Antes de realizar el ajuste de hiperparámetros, primeramente buscaremos los modelos de KNN y Árboles de Decisión con los hiperparámetros por defecto."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejores parámetros: {'classifier__metric': 'minkowski', 'classifier__n_neighbors': 5, 'classifier__weights': 'uniform'}\n",
            "Mejor puntuación: 0.5883600917431192\n",
            "Tiempo de ejecución: 0.06190776824951172 segundos\n",
            "Mejores parámetros: {'classifier__criterion': 'gini', 'classifier__max_depth': None, 'classifier__min_impurity_decrease': 0.0, 'classifier__min_samples_split': 2}\n",
            "Mejor puntuación: 0.7611126101816873\n",
            "Tiempo de ejecución: 0.0910196304321289 segundos\n"
          ]
        }
      ],
      "source": [
        "# Definimos los clasificadores KNN y DecisionTreeClassifier\n",
        "clasificadores = [KNeighborsClassifier(), DecisionTreeClassifier()]\n",
        "\n",
        "# Definimos el codificador de variables categóricas\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "       (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "       ])\n",
        "\n",
        "# Definimos el mejor escalador e imputador obtenidos anteriormente\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "       (\"imputer\", mejor_imputer), \n",
        "       (\"scaler\", mejor_scaler)\n",
        "       ])\n",
        "\n",
        "# Preprocesador combinado para columnas numéricas y categóricas\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "       (\"num\", numerical_transformer, numericas), \n",
        "       (\"cat\", categorical_transformer, categoricas)\n",
        "       ])\n",
        "\n",
        "# Iteramos sobre los clasificadores\n",
        "for clasificador in clasificadores:\n",
        "\n",
        "    # Pipeline completo con clasificador\n",
        "    pipeline = Pipeline(steps=[\n",
        "           (\"preprocessor\", preprocessor), \n",
        "           (\"classifier\", clasificador)\n",
        "           ])\n",
        "    \n",
        "    # Definimos los hiperparámetros por defecto para GridSearch\n",
        "    if isinstance(clasificador, KNeighborsClassifier):\n",
        "            param_grid = {\n",
        "                'classifier__n_neighbors': [5],\n",
        "                'classifier__weights': ['uniform'],\n",
        "                'classifier__metric': ['minkowski']\n",
        "            }\n",
        "    elif isinstance(clasificador, DecisionTreeClassifier):\n",
        "            param_grid = {\n",
        "                'classifier__criterion': ['gini'],\n",
        "                'classifier__max_depth': [None],\n",
        "                'classifier__min_samples_split': [2],\n",
        "                'classifier__min_impurity_decrease': [0.0]\n",
        "            }\n",
        "    \n",
        "    # Usamos GridSearchCV para encontrar los mejores hiperparámetros\n",
        "    label_encoder = LabelEncoder()\n",
        "    y_train = label_encoder.fit_transform(y_train)\n",
        "    y_test = label_encoder.transform(y_test)\n",
        "    grid_search = GridSearchCV(pipeline, param_grid, cv=3, n_jobs=-1, scoring='balanced_accuracy')\n",
        "    \n",
        "    # Medimos el tiempo de entrenamiento del modelo\n",
        "    start_time = time.time()\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    end_time = time.time()\n",
        "    print(\"Mejores parámetros:\", grid_search.best_params_)\n",
        "    print(\"Mejor puntuación:\", grid_search.best_score_)\n",
        "    print(\"Tiempo de ejecución:\", end_time - start_time, \"segundos\")\n",
        "# Mostrar los mejores hiperparámetros"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57Bqmm-NWzKQ",
        "outputId": "4c704e4a-80da-4ec6-b14c-f2d940629eab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejores parámetros: {'classifier__metric': 'manhattan', 'classifier__n_neighbors': 5, 'classifier__weights': 'distance'}\n",
            "Mejor puntuación: 0.8067087155963303\n",
            "Tiempo de ejecución: 0.8216135501861572 segundos\n",
            "Mejores parámetros: {'classifier__criterion': 'entropy', 'classifier__max_depth': None, 'classifier__min_impurity_decrease': 0.0, 'classifier__min_samples_split': 2}\n",
            "Mejor puntuación: 0.7724180383162439\n",
            "Tiempo de ejecución: 1.4485673904418945 segundos\n"
          ]
        }
      ],
      "source": [
        "# Creamos los clasificadores principales (KNN y Árboles de decisión)\n",
        "clasificadores = [KNeighborsClassifier(), DecisionTreeClassifier()]\n",
        "\n",
        "# Definimos el codificador de variables categóricas\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "       (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "       ])\n",
        "\n",
        "# Definimos el mejor escalador e imputador obtenidos anteriormente en una pipeline\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "       (\"imputer\", mejor_imputer), \n",
        "       (\"scaler\", mejor_scaler)\n",
        "       ])\n",
        "\n",
        "# Preprocesador combinado para columnas numéricas y categóricas\n",
        "preprocessor = ColumnTransformer(transformers=[\n",
        "       (\"num\", numerical_transformer, numericas), \n",
        "       (\"cat\", categorical_transformer, categoricas)\n",
        "       ])\n",
        "\n",
        "# Iteramos sobre los clasificadores\n",
        "for clasificador in clasificadores:\n",
        "\n",
        "    # Definimos una pipeline con el preprocesador y el clasificador\n",
        "    pipeline = Pipeline(steps=[\n",
        "           (\"preprocessor\", preprocessor), \n",
        "           (\"classifier\", clasificador)\n",
        "           ])\n",
        "    \n",
        "    # Definimos la rejilla de hiperparámetros para cada clasificador\n",
        "    if isinstance(clasificador, KNeighborsClassifier):\n",
        "            param_grid = {\n",
        "                'classifier__n_neighbors': [3, 5, 7, 9, 11],\n",
        "                'classifier__weights': ['uniform', 'distance'],\n",
        "                'classifier__metric': ['minkowski', 'euclidean', 'manhattan']\n",
        "            }\n",
        "    elif isinstance(clasificador, DecisionTreeClassifier):\n",
        "            param_grid = {\n",
        "                'classifier__criterion': ['gini', 'entropy'],\n",
        "                'classifier__max_depth': [5, 10, 15, None],\n",
        "                'classifier__min_samples_split': [2, 5, 10],\n",
        "                'classifier__min_impurity_decrease': [0.0, 0.01, 0.02]\n",
        "            }\n",
        "            \n",
        "    # Entrenamos el modelo con GridSearchCV para encontrar los mejores hiperparámetros\n",
        "    label_encoder = LabelEncoder()\n",
        "    y_train = label_encoder.fit_transform(y_train)\n",
        "    y_test = label_encoder.transform(y_test)\n",
        "    grid_search = GridSearchCV(pipeline, param_grid, cv=3, n_jobs=-1, scoring='balanced_accuracy')\n",
        "    \n",
        "    # Medimos el tiempo del entrenamiento del modelo\n",
        "    start_time = time.time()\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Mostrar los mejores hiperparámetros\n",
        "    print(\"Mejores parámetros:\", grid_search.best_params_)\n",
        "    print(\"Mejor puntuación:\", grid_search.best_score_)\n",
        "    print(\"Tiempo de ejecución:\", end_time - start_time, \"segundos\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSjLo59iopY6"
      },
      "source": [
        "Vamos a comprobar los resultados obtenidos con el formato dummy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jovm0KWqL8K",
        "outputId": "adcf33fc-cdd3-4f22-f5f9-d58b4e6aedf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mejores parámetros: {'classifier__constant': 1, 'classifier__strategy': 'uniform'}\n",
            "Mejor puntuación: 0.5223320291419321\n",
            "Tiempo de ejecución: 0.28276777267456055 segundos\n"
          ]
        }
      ],
      "source": [
        "y_train = datos[\"Attrition\"].iloc[X_train.index]  # Assuming X_train.index holds the original indices\n",
        "y_test = datos[\"Attrition\"].iloc[X_test.index]  # Assuming X_test.index holds the original indices\n",
        "\n",
        "pipeline = Pipeline(steps=[(\"preprocessor\", preprocessor), (\"classifier\", DummyClassifier())])\n",
        "param_grid = {\n",
        "    'classifier__strategy': ['most_frequent', 'stratified', 'prior', 'uniform',  # Removed 'constant'\n",
        "                            'constant'],  # Added 'constant' back with a constant value\n",
        "    'classifier__constant': [0, 1] if 'constant' in ['most_frequent', 'stratified', 'prior', 'uniform', 'constant'] else [] # Specify constant values only when 'constant' strategy is used\n",
        "}\n",
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)  # Encode y_train for the DummyClassifier\n",
        "y_test_encoded = label_encoder.transform(y_test)\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=3, n_jobs=-1, scoring='balanced_accuracy', error_score='raise')\n",
        "start_time = time.time()\n",
        "grid_search.fit(X_train, y_train_encoded)\n",
        "dummy_pred = grid_search.predict(X_test)\n",
        "end_time = time.time()\n",
        "\n",
        "print(\"Mejores parámetros:\", grid_search.best_params_)\n",
        "print(\"Mejor puntuación:\", grid_search.best_score_)\n",
        "print(\"Tiempo de ejecución:\", end_time - start_time, \"segundos\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUfX_kb9WGRB"
      },
      "source": [
        "# Avanzados: Modelos lineales y SVM's"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
