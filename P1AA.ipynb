{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/100495802/G11.AA-495802-495702/blob/main/P1AA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5SpM5Zk6CIBr"
      },
      "source": [
        "# P1-AA: PREDICCIÓN DEL ABANDONO DE EMPLEADOS DE UNA EMPRESA\n",
        "- Curso de Aprendizaje Automático 2024/25\n",
        "- Grado en Ingeniería Informática - UC3M\n",
        "- Alejandro López Sancho: 100495702\n",
        "- Javier Rosales Lozano: 100495802"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FioRDksKCIBt"
      },
      "source": [
        "## 1. Introducción y carga de datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.1. Enunciado del proyecto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isNVNy5ICIBu"
      },
      "source": [
        "El siguiente notebook contiene toda la información y trabajo realizado acerca de la primera parte de la práctica inicial del curso de Aprendizaje Automático 2024/25. El objetivo de esta práctica es realizar la __construcción, medición y evaluación de un modelo que prediga un problema planteado como el número de abandonos dentro de una empresa en función de las características de sus trabajadores__.\n",
        "\n",
        "En este primer archivo de Jupyter Notebook encontraremos todo el proceso de EDA (Exploratory Data Analysis), selección de imputers y scalers, ajuste de hiperparámetros, evaluación de modelos, obtención de la tasa de aprendizaje y resolución de las preguntas establecidas en el enunciado de la práctica."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAdFsjFhCIBv"
      },
      "source": [
        "### 1.2. Repositorio Github y Dataset Inicial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El siguiente enlace redirige al [repositorio Github](https://github.com/100495802/G11.AA-495802-495702.git) correspondiente al proyecto; los datos elegidos para la realización del proyecto corresponden con el estándar especificado para la realización del trabajo (suma de los dos últimos dígitos de uno de los NIAs del grupo de prácticas). En este caso, hemos elegido el NIA __100495702__, por lo que nuestro [dataset inicial](attrition_availabledata_02.csv.gz) corresponderá con el número _2_ del conjunto de datasets del Aula Global."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkvWftzzAVYR"
      },
      "source": [
        "### 1.3. Carga de Datos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A continuación, nos disponemos a la __carga de este conjunto de datos__:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 201,
      "metadata": {
        "id": "SWvqYujY3lYu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "datos = pd.read_csv(\"attrition_availabledata_02.csv.gz\", compression=\"gzip\", sep=\",\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.4. Conversión de variables categóricas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Debido a que la variable de salida _Attrition_ es una variable categórica, esto no va a ser funcional cuando realicemos algunas metodologías más adelante (GridSearch en HPO), por lo que convertiremos estas a una codificación binaria."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 202,
      "metadata": {},
      "outputs": [],
      "source": [
        "datos['Attrition'] = datos['Attrition'].map({'Yes': 1, 'No': 0})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LYoIph_A4hU"
      },
      "source": [
        "# 2. EDA Simplificado"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pUti9QodCIBz"
      },
      "source": [
        "Una vez cargado el dataset, nos disponemos a comentar y describir los distintos datos que existen en el dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43xv2WeM6CnM"
      },
      "source": [
        "### 2.1. Análisis general del dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Vamos a investigar primeramente el tamaño del dataset; esto lo haremos con los atributos de la librería Pandas `.shape` y `.size`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 203,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aua0Xb5UCIBz",
        "outputId": "7000c9fc-e8c1-41da-9c33-d131290279e4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tamaño del dataset: (2940, 31)\n",
            "Número total de elementos del dataset: 91140\n"
          ]
        }
      ],
      "source": [
        "print(f\"Tamaño del dataset: {datos.shape}\")\n",
        "print(f\"Número total de elementos del dataset: {datos.size}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GKWnqmwlCIB0"
      },
      "source": [
        "Podemos observar que el tamaño del dataset es de __2940 filas (instancias) y 31 columnas (atributos)__. También identificamos el número de elementos del conjunto de datos.\n",
        "\n",
        "Seguidamente, echaremos un vistazo rápido a los atributos que hay en la base de datos; usaremos el método `info()` para identificar las diferentes columnas del dataset, además del tipo de dato y el número de instancias no nulas que contiene."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 204,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGsKcVKh78gf",
        "outputId": "d30b53b4-ecbc-4e9d-fe0b-e44d005b9310"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2940 entries, 0 to 2939\n",
            "Data columns (total 31 columns):\n",
            " #   Column                   Non-Null Count  Dtype  \n",
            "---  ------                   --------------  -----  \n",
            " 0   hrs                      2940 non-null   float64\n",
            " 1   absences                 2940 non-null   int64  \n",
            " 2   JobInvolvement           2940 non-null   int64  \n",
            " 3   PerformanceRating        2940 non-null   int64  \n",
            " 4   EnvironmentSatisfaction  2927 non-null   float64\n",
            " 5   JobSatisfaction          2925 non-null   float64\n",
            " 6   WorkLifeBalance          2911 non-null   float64\n",
            " 7   Age                      2940 non-null   int64  \n",
            " 8   BusinessTravel           2940 non-null   object \n",
            " 9   Department               2940 non-null   object \n",
            " 10  DistanceFromHome         2940 non-null   int64  \n",
            " 11  Education                2940 non-null   int64  \n",
            " 12  EducationField           2940 non-null   object \n",
            " 13  EmployeeCount            2940 non-null   int64  \n",
            " 14  EmployeeID               2940 non-null   int64  \n",
            " 15  Gender                   2940 non-null   object \n",
            " 16  JobLevel                 2940 non-null   int64  \n",
            " 17  JobRole                  2940 non-null   object \n",
            " 18  MaritalStatus            2940 non-null   object \n",
            " 19  MonthlyIncome            2940 non-null   int64  \n",
            " 20  NumCompaniesWorked       2926 non-null   float64\n",
            " 21  Over18                   2940 non-null   object \n",
            " 22  PercentSalaryHike        2940 non-null   int64  \n",
            " 23  StandardHours            2940 non-null   int64  \n",
            " 24  StockOptionLevel         2940 non-null   int64  \n",
            " 25  TotalWorkingYears        2935 non-null   float64\n",
            " 26  TrainingTimesLastYear    2940 non-null   int64  \n",
            " 27  YearsAtCompany           2940 non-null   int64  \n",
            " 28  YearsSinceLastPromotion  2940 non-null   int64  \n",
            " 29  YearsWithCurrManager     2940 non-null   int64  \n",
            " 30  Attrition                2940 non-null   int64  \n",
            "dtypes: float64(6), int64(18), object(7)\n",
            "memory usage: 712.2+ KB\n"
          ]
        }
      ],
      "source": [
        "datos.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtI1k54KCIB0"
      },
      "source": [
        "En la salida podemos observar una tabla donde apreciamos el nombre del atirbuto, el número de instancias no vacías y el tipo de dato de ésta columna. Esto nos servirá para apreciar los tipos de datos que estamos analizando.\n",
        "\n",
        "Podemos observar que algunos de ellos cumplen con todas sus filas con algún valor no nulo (N/A), mientras que __otras columnas no alcanzan el número total de filas obtenido anteriormente (2940)__.\n",
        "\n",
        "Por otro lado, el tipo de datos nos hace preveer cuáles columnas representan __atributos categóricos__ (`object`) y cuáles __atributos numéricos__ (`int64`, `float64`).\n",
        "\n",
        "Para un resumen más detallado, nos serviremos de otro método de Pandas: `.describe()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 205,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 349
        },
        "id": "bj5Iv-POWqDw",
        "outputId": "ec806b61-4caa-4e38-c363-c38098b46aa1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hrs</th>\n",
              "      <th>absences</th>\n",
              "      <th>JobInvolvement</th>\n",
              "      <th>PerformanceRating</th>\n",
              "      <th>EnvironmentSatisfaction</th>\n",
              "      <th>JobSatisfaction</th>\n",
              "      <th>WorkLifeBalance</th>\n",
              "      <th>Age</th>\n",
              "      <th>DistanceFromHome</th>\n",
              "      <th>Education</th>\n",
              "      <th>...</th>\n",
              "      <th>NumCompaniesWorked</th>\n",
              "      <th>PercentSalaryHike</th>\n",
              "      <th>StandardHours</th>\n",
              "      <th>StockOptionLevel</th>\n",
              "      <th>TotalWorkingYears</th>\n",
              "      <th>TrainingTimesLastYear</th>\n",
              "      <th>YearsAtCompany</th>\n",
              "      <th>YearsSinceLastPromotion</th>\n",
              "      <th>YearsWithCurrManager</th>\n",
              "      <th>Attrition</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>2940.000000</td>\n",
              "      <td>2940.000000</td>\n",
              "      <td>2940.000000</td>\n",
              "      <td>2940.000000</td>\n",
              "      <td>2927.000000</td>\n",
              "      <td>2925.000000</td>\n",
              "      <td>2911.000000</td>\n",
              "      <td>2940.000000</td>\n",
              "      <td>2940.000000</td>\n",
              "      <td>2940.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>2926.000000</td>\n",
              "      <td>2940.000000</td>\n",
              "      <td>2940.0</td>\n",
              "      <td>2940.000000</td>\n",
              "      <td>2935.000000</td>\n",
              "      <td>2940.000000</td>\n",
              "      <td>2940.000000</td>\n",
              "      <td>2940.000000</td>\n",
              "      <td>2940.000000</td>\n",
              "      <td>2940.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>7.322768</td>\n",
              "      <td>12.706803</td>\n",
              "      <td>2.728571</td>\n",
              "      <td>3.154422</td>\n",
              "      <td>2.723266</td>\n",
              "      <td>2.746325</td>\n",
              "      <td>2.760907</td>\n",
              "      <td>36.861224</td>\n",
              "      <td>9.305102</td>\n",
              "      <td>2.906463</td>\n",
              "      <td>...</td>\n",
              "      <td>2.664388</td>\n",
              "      <td>15.187075</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.785034</td>\n",
              "      <td>11.363884</td>\n",
              "      <td>2.798639</td>\n",
              "      <td>7.095578</td>\n",
              "      <td>2.227891</td>\n",
              "      <td>4.191156</td>\n",
              "      <td>0.161224</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.335600</td>\n",
              "      <td>5.533199</td>\n",
              "      <td>0.716167</td>\n",
              "      <td>0.361414</td>\n",
              "      <td>1.096170</td>\n",
              "      <td>1.104612</td>\n",
              "      <td>0.713539</td>\n",
              "      <td>9.286733</td>\n",
              "      <td>8.201638</td>\n",
              "      <td>1.023254</td>\n",
              "      <td>...</td>\n",
              "      <td>2.495153</td>\n",
              "      <td>3.661275</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.851343</td>\n",
              "      <td>7.897032</td>\n",
              "      <td>1.304166</td>\n",
              "      <td>6.161878</td>\n",
              "      <td>3.274101</td>\n",
              "      <td>3.627734</td>\n",
              "      <td>0.367800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>5.416880</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>11.000000</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>6.272786</td>\n",
              "      <td>8.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>30.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>12.000000</td>\n",
              "      <td>8.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>7.032627</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>35.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>7.948416</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>43.000000</td>\n",
              "      <td>14.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>18.000000</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>16.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>7.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>10.937261</td>\n",
              "      <td>24.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>60.000000</td>\n",
              "      <td>29.000000</td>\n",
              "      <td>5.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>9.000000</td>\n",
              "      <td>25.000000</td>\n",
              "      <td>8.0</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>6.000000</td>\n",
              "      <td>40.000000</td>\n",
              "      <td>15.000000</td>\n",
              "      <td>17.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>8 rows × 24 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "               hrs     absences  JobInvolvement  PerformanceRating  \\\n",
              "count  2940.000000  2940.000000     2940.000000        2940.000000   \n",
              "mean      7.322768    12.706803        2.728571           3.154422   \n",
              "std       1.335600     5.533199        0.716167           0.361414   \n",
              "min       5.416880     1.000000        1.000000           3.000000   \n",
              "25%       6.272786     8.000000        2.000000           3.000000   \n",
              "50%       7.032627    13.000000        3.000000           3.000000   \n",
              "75%       7.948416    17.000000        3.000000           3.000000   \n",
              "max      10.937261    24.000000        4.000000           4.000000   \n",
              "\n",
              "       EnvironmentSatisfaction  JobSatisfaction  WorkLifeBalance          Age  \\\n",
              "count              2927.000000      2925.000000      2911.000000  2940.000000   \n",
              "mean                  2.723266         2.746325         2.760907    36.861224   \n",
              "std                   1.096170         1.104612         0.713539     9.286733   \n",
              "min                   1.000000         1.000000         1.000000    18.000000   \n",
              "25%                   2.000000         2.000000         2.000000    30.000000   \n",
              "50%                   3.000000         3.000000         3.000000    35.000000   \n",
              "75%                   4.000000         4.000000         3.000000    43.000000   \n",
              "max                   4.000000         4.000000         4.000000    60.000000   \n",
              "\n",
              "       DistanceFromHome    Education  ...  NumCompaniesWorked  \\\n",
              "count       2940.000000  2940.000000  ...         2926.000000   \n",
              "mean           9.305102     2.906463  ...            2.664388   \n",
              "std            8.201638     1.023254  ...            2.495153   \n",
              "min            1.000000     1.000000  ...            0.000000   \n",
              "25%            2.000000     2.000000  ...            1.000000   \n",
              "50%            7.000000     3.000000  ...            2.000000   \n",
              "75%           14.000000     4.000000  ...            4.000000   \n",
              "max           29.000000     5.000000  ...            9.000000   \n",
              "\n",
              "       PercentSalaryHike  StandardHours  StockOptionLevel  TotalWorkingYears  \\\n",
              "count        2940.000000         2940.0       2940.000000        2935.000000   \n",
              "mean           15.187075            8.0          0.785034          11.363884   \n",
              "std             3.661275            0.0          0.851343           7.897032   \n",
              "min            11.000000            8.0          0.000000           0.000000   \n",
              "25%            12.000000            8.0          0.000000           6.000000   \n",
              "50%            14.000000            8.0          1.000000          10.000000   \n",
              "75%            18.000000            8.0          1.000000          16.000000   \n",
              "max            25.000000            8.0          3.000000          40.000000   \n",
              "\n",
              "       TrainingTimesLastYear  YearsAtCompany  YearsSinceLastPromotion  \\\n",
              "count            2940.000000     2940.000000              2940.000000   \n",
              "mean                2.798639        7.095578                 2.227891   \n",
              "std                 1.304166        6.161878                 3.274101   \n",
              "min                 0.000000        0.000000                 0.000000   \n",
              "25%                 2.000000        3.000000                 0.000000   \n",
              "50%                 3.000000        5.000000                 1.000000   \n",
              "75%                 3.000000       10.000000                 3.000000   \n",
              "max                 6.000000       40.000000                15.000000   \n",
              "\n",
              "       YearsWithCurrManager    Attrition  \n",
              "count           2940.000000  2940.000000  \n",
              "mean               4.191156     0.161224  \n",
              "std                3.627734     0.367800  \n",
              "min                0.000000     0.000000  \n",
              "25%                2.000000     0.000000  \n",
              "50%                3.000000     0.000000  \n",
              "75%                7.000000     0.000000  \n",
              "max               17.000000     1.000000  \n",
              "\n",
              "[8 rows x 24 columns]"
            ]
          },
          "execution_count": 205,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "datos.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bpXAnD26CIB1"
      },
      "source": [
        "Ésta ejecución de código nos permite identificar algunas __métricas estadísticas__ acerca del conjunto de datos que abarcan los distintos atributos (como la media, la mediana, mínimos, máximos y rangos intercuartílicos). Esto de momento no nos servirá, pero quizás más adelante será útil.\n",
        "\n",
        "Con los datos visualizados anteriormente en la ejecución de `.info()`, vamos a observar los valores de las variables más a fondo, haciendo hincapié en las distintas observaciones que se piden en la práctica."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2. Variables numéricas y categóricas; variables con alta cardinalidad"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40O-bNrXCIB1"
      },
      "source": [
        "Empezamos distinguiendo los atributos que representan __valores categóricos__ de los que representan __valores numéricos__ (descartando la columna de la variable de salida, _Attrition_, la cual sabemos que es categórica):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 206,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNnSTQQQbP0p",
        "outputId": "29c9d39b-0c25-4dec-a2d6-bc9709487791"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['hrs', 'absences', 'JobInvolvement', 'PerformanceRating',\n",
            "       'EnvironmentSatisfaction', 'JobSatisfaction', 'WorkLifeBalance', 'Age',\n",
            "       'DistanceFromHome', 'Education', 'EmployeeCount', 'EmployeeID',\n",
            "       'JobLevel', 'MonthlyIncome', 'NumCompaniesWorked', 'PercentSalaryHike',\n",
            "       'StandardHours', 'StockOptionLevel', 'TotalWorkingYears',\n",
            "       'TrainingTimesLastYear', 'YearsAtCompany', 'YearsSinceLastPromotion',\n",
            "       'YearsWithCurrManager'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "numericas = datos.select_dtypes(include=['int64', 'float64']).columns.drop(['Attrition'])\n",
        "print(numericas)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 207,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEdrwVfGGsWx",
        "outputId": "1a3693e7-df07-46bf-fd53-a5a71dfed2ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Index(['BusinessTravel', 'Department', 'EducationField', 'Gender', 'JobRole',\n",
            "       'MaritalStatus', 'Over18'],\n",
            "      dtype='object')\n"
          ]
        }
      ],
      "source": [
        "categoricas = datos.select_dtypes(include=[\"object\"]).columns\n",
        "print(categoricas)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrB0wuSW6dzQ"
      },
      "source": [
        "A continuación, de las __variables categóricas__, vamos a identificar aquellas variables con una __alta cardinalidad__ en sus valores:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 208,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EBkwR4EyZAf3",
        "outputId": "4871f567-249e-40cf-8b8d-e49928c8d443"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BusinessTravel\n",
            "['Travel_Frequently' 'Non-Travel' 'Travel_Rarely']\n",
            "Department\n",
            "['Research & Development' 'Sales' 'Human Resources']\n",
            "EducationField\n",
            "['Life Sciences' 'Medical' 'Other' 'Technical Degree' 'Marketing'\n",
            " 'Human Resources']\n",
            "Gender\n",
            "['Male' 'Female']\n",
            "JobRole\n",
            "['Laboratory Technician' 'Healthcare Representative' 'Research Scientist'\n",
            " 'Sales Representative' 'Manufacturing Director' 'Sales Executive'\n",
            " 'Research Director' 'Human Resources' 'Manager']\n",
            "MaritalStatus\n",
            "['Married' 'Divorced' 'Single']\n",
            "Over18\n",
            "['Y']\n"
          ]
        }
      ],
      "source": [
        "for columna in datos.select_dtypes(include=[\"object\"]).columns:\n",
        "    print(columna)\n",
        "    print(datos[columna].unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dx3V04UPCIB2"
      },
      "source": [
        "Analizando la salida de esta ejecución, podemos observar qué variables categóricas presentan elevada cardinalidad. __En este proyecto consideraremos con cardinalidad elevada un atributo con rango de posibles opciones mayor de 4__.\n",
        "\n",
        "En este caso, las columnas con alta cardinalidad son _EducationField_ y _JobRole_."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3. Variables nulas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UnAB60GjZXKI"
      },
      "source": [
        "Para el preprocesado de datos, es importante determinar qué instancias contienen __valores nulos__, y el número de instancias de este tipo en cada columna. Esto lo comprobamos con el método de Pandas `.isnull()`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 209,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "lJo1LEBiHUn8",
        "outputId": "42939790-46a7-4624-8705-d7898874e8c8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "EnvironmentSatisfaction    13\n",
              "JobSatisfaction            15\n",
              "WorkLifeBalance            29\n",
              "NumCompaniesWorked         14\n",
              "TotalWorkingYears           5\n",
              "dtype: int64"
            ]
          },
          "execution_count": 209,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "nulos = datos.isnull().sum()\n",
        "nulos[nulos > 0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bMO0HTDiXN0t"
      },
      "source": [
        "Como podemos observar, en el dataset se aprecian __cinco columnas con valores nulos__ en sus filas: _EnvironmentSatisfaction, JobSatisfaction, WorkLifeBalance, NumCompaniesWorked, TotalWorkingYears_. Teniendo en cuenta que en total hay 2940 filas en la base de datos, se pueden calcular fácilmente la media de datos vacíos por columna.\n",
        "\n",
        "Si recordamos de qué tipo era cada variable, podemos observar que __todas estas columnas corresponden con variables numéricas__, y podemos ir pensando ya en posibilidades para trabajar con estos valores vacíos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.4. Variables de identificación (ID)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGssnEPeCIB2"
      },
      "source": [
        "Una vez analizado todo lo anterior, empezamos a buscar qué posibles columnas actúan como identificadores en la base de datos. A simple vista, una posible opción sería _EmployeeID_, aunque es mejor comprobarlo con la llamada al método `.nunique()`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 210,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tLbSgDVZcUId",
        "outputId": "7eb35495-ccb6-4fb9-d847-eefcd4c598b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "La columna 'EmployeeID' es un posible identificador único.\n"
          ]
        }
      ],
      "source": [
        "for columna in datos.columns:\n",
        "    if datos[columna].nunique() == len(datos):\n",
        "        print(f\"La columna '{columna}' es un posible identificador único.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 211,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565
        },
        "id": "DuI1DXLICIB3",
        "outputId": "f28fa3f6-4f8a-44f4-c4ad-fdf00807343c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>hrs</th>\n",
              "      <th>absences</th>\n",
              "      <th>JobInvolvement</th>\n",
              "      <th>PerformanceRating</th>\n",
              "      <th>EnvironmentSatisfaction</th>\n",
              "      <th>JobSatisfaction</th>\n",
              "      <th>WorkLifeBalance</th>\n",
              "      <th>Age</th>\n",
              "      <th>BusinessTravel</th>\n",
              "      <th>Department</th>\n",
              "      <th>...</th>\n",
              "      <th>Over18</th>\n",
              "      <th>PercentSalaryHike</th>\n",
              "      <th>StandardHours</th>\n",
              "      <th>StockOptionLevel</th>\n",
              "      <th>TotalWorkingYears</th>\n",
              "      <th>TrainingTimesLastYear</th>\n",
              "      <th>YearsAtCompany</th>\n",
              "      <th>YearsSinceLastPromotion</th>\n",
              "      <th>YearsWithCurrManager</th>\n",
              "      <th>Attrition</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10.060048</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>31</td>\n",
              "      <td>Travel_Frequently</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>23</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>7.0</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9.437671</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>33</td>\n",
              "      <td>Non-Travel</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>13</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7.900932</td>\n",
              "      <td>20</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>35</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>22</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>10.0</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7.193853</td>\n",
              "      <td>19</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>28</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>15</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6.979201</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>31</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>12</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2935</th>\n",
              "      <td>9.400915</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>3.0</td>\n",
              "      <td>42</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>Sales</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>14</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>10.0</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>7</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2936</th>\n",
              "      <td>6.934386</td>\n",
              "      <td>9</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>49</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>11</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>16.0</td>\n",
              "      <td>3</td>\n",
              "      <td>15</td>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2937</th>\n",
              "      <td>9.106920</td>\n",
              "      <td>15</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>36</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>Sales</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>13</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>18.0</td>\n",
              "      <td>2</td>\n",
              "      <td>18</td>\n",
              "      <td>4</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2938</th>\n",
              "      <td>6.532645</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>30</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>Sales</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>16</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2939</th>\n",
              "      <td>6.542739</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>37</td>\n",
              "      <td>Travel_Rarely</td>\n",
              "      <td>Research &amp; Development</td>\n",
              "      <td>...</td>\n",
              "      <td>Y</td>\n",
              "      <td>11</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2940 rows × 30 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            hrs  absences  JobInvolvement  PerformanceRating  \\\n",
              "0     10.060048         6               3                  4   \n",
              "1      9.437671         2               2                  3   \n",
              "2      7.900932        20               3                  4   \n",
              "3      7.193853        19               4                  3   \n",
              "4      6.979201         8               3                  3   \n",
              "...         ...       ...             ...                ...   \n",
              "2935   9.400915         3               2                  3   \n",
              "2936   6.934386         9               2                  3   \n",
              "2937   9.106920        15               3                  3   \n",
              "2938   6.532645         6               4                  3   \n",
              "2939   6.542739         6               3                  3   \n",
              "\n",
              "      EnvironmentSatisfaction  JobSatisfaction  WorkLifeBalance  Age  \\\n",
              "0                         2.0              4.0              1.0   31   \n",
              "1                         3.0              4.0              3.0   33   \n",
              "2                         3.0              4.0              3.0   35   \n",
              "3                         4.0              2.0              3.0   28   \n",
              "4                         2.0              4.0              2.0   31   \n",
              "...                       ...              ...              ...  ...   \n",
              "2935                      4.0              NaN              3.0   42   \n",
              "2936                      3.0              1.0              2.0   49   \n",
              "2937                      2.0              4.0              2.0   36   \n",
              "2938                      1.0              3.0              2.0   30   \n",
              "2939                      3.0              4.0              4.0   37   \n",
              "\n",
              "         BusinessTravel              Department  ...  Over18  \\\n",
              "0     Travel_Frequently  Research & Development  ...       Y   \n",
              "1            Non-Travel  Research & Development  ...       Y   \n",
              "2         Travel_Rarely  Research & Development  ...       Y   \n",
              "3         Travel_Rarely  Research & Development  ...       Y   \n",
              "4         Travel_Rarely  Research & Development  ...       Y   \n",
              "...                 ...                     ...  ...     ...   \n",
              "2935      Travel_Rarely                   Sales  ...       Y   \n",
              "2936      Travel_Rarely  Research & Development  ...       Y   \n",
              "2937      Travel_Rarely                   Sales  ...       Y   \n",
              "2938      Travel_Rarely                   Sales  ...       Y   \n",
              "2939      Travel_Rarely  Research & Development  ...       Y   \n",
              "\n",
              "      PercentSalaryHike StandardHours  StockOptionLevel TotalWorkingYears  \\\n",
              "0                    23             8                 1               7.0   \n",
              "1                    13             8                 0               7.0   \n",
              "2                    22             8                 1              10.0   \n",
              "3                    15             8                 0               1.0   \n",
              "4                    12             8                 1              10.0   \n",
              "...                 ...           ...               ...               ...   \n",
              "2935                 14             8                 1              10.0   \n",
              "2936                 11             8                 1              16.0   \n",
              "2937                 13             8                 0              18.0   \n",
              "2938                 16             8                 1               5.0   \n",
              "2939                 11             8                 0               7.0   \n",
              "\n",
              "      TrainingTimesLastYear YearsAtCompany YearsSinceLastPromotion  \\\n",
              "0                         5              2                       2   \n",
              "1                         6              6                       1   \n",
              "2                         4             10                       7   \n",
              "3                         1              1                       0   \n",
              "4                         2              8                       7   \n",
              "...                     ...            ...                     ...   \n",
              "2935                      2              9                       7   \n",
              "2936                      3             15                       5   \n",
              "2937                      2             18                       4   \n",
              "2938                      2              5                       0   \n",
              "2939                      2              5                       0   \n",
              "\n",
              "      YearsWithCurrManager  Attrition  \n",
              "0                        2          1  \n",
              "1                        2          0  \n",
              "2                        7          1  \n",
              "3                        0          0  \n",
              "4                        7          0  \n",
              "...                    ...        ...  \n",
              "2935                     8          0  \n",
              "2936                    11          0  \n",
              "2937                    11          0  \n",
              "2938                     4          0  \n",
              "2939                     1          0  \n",
              "\n",
              "[2940 rows x 30 columns]"
            ]
          },
          "execution_count": 211,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "datos.drop(columns=\"EmployeeID\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQZuc7xPCIB3"
      },
      "source": [
        "Nuestras sospechas han resultado ser ciertas, y es que es el único atributo cuyos valores son únicos, y no coinciden dos o más instancias con el mismo valor en esta columna. Más adelante decidiremos qué hacer con esta columna."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.5. ¿Problema desbalanceado?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRq368dLCIB3"
      },
      "source": [
        "Con el planteamiento completo del enunciado se puede intuir que estamos ante un __problema de clasificación__. Además, la variable _Attrition_ es la que determinará si un empleado es propenso a abandonar la empresa en función del resto de columnas.\n",
        "\n",
        "Sin embargo, todavía __no podemos comprobar si se trata de un problema de clasificación desbalanceado__, ya que no hemos hecho un conteo de los valores de dicha columna. Este paso es importante, ya que marcará la manera en la que realizaremos las particiones para entrenar, validar y evaluar el modelo.\n",
        "\n",
        "Para averiguarlo, usaremos el método `.value_counts()`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 212,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 178
        },
        "id": "_Q-zUraNevYv",
        "outputId": "6a9e4bbe-9e7c-442f-e611-f6c2c3f16027"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Attrition\n",
              "0    2466\n",
              "1     474\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 212,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "datos[\"Attrition\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wzo6vjRvCIB3"
      },
      "source": [
        "La salida de la ejecución nos muestra el conteo de datos de dicha columna, lo que demuestra que __se trata de un problema desbalanceado__ hacia el valor \"no\", siendo más del 80% de las clasificaciones de este tipo.\n",
        "\n",
        "Esto va a influir en la manera en la que creamos los modelos de aprendizaje, ya que deberemos establecer los pesos balanceados con `class_weight=balanced`; de esta manera, se dará prioridad a las instancias de la clase minoritaria."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PM_aqdJECIB3"
      },
      "source": [
        "## 3. Metodología de trabajo: Decidir cómo se va a realizar la evaluación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTaYmNfae8R8"
      },
      "source": [
        "Una vez terminada la parte de análisis del conjunto de datos, podemos concluir en dos cosas:\n",
        "\n",
        "1. El problema es de clasificación, desbalanceado, con variables categóricas y numéricas, y algunas instancias contienen datos vacíos.\n",
        "\n",
        "2. Siendo el 80% de la muestra la que decide no abandonar, por el momento, la empresa puede estar tranquila.\n",
        "\n",
        "Con los datos ya analizados, procedemos a especificar la realización de la práctica. En este apartado vamos a comentar __cómo vamos a evaluar nuestro modelo__."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1. Planificación del entrenamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "akCIMtyuDCPx"
      },
      "source": [
        "- __División de los datos:__\n",
        "\n",
        "  Para realizar la evaluación de nuestro modelo, lo primero que tenemos que hacer es dividir el conjunto de datos en dos particiones de train y test. Usaremos __Holdout__ para invertir 2/3 de los datos para la parte de entrenamiento del modelo y el resto para evaluar el modelo final del entrenamiento.\n",
        "\n",
        "- __Preprocesado de datos:__\n",
        "\n",
        "  Para empezar con la fase de entrenamiento, primero deberemos ajustar unas métricas relacionadas con el dataset. Deberemos medir qué método de __imputación__ y __escalado__ de atributos genera un mejor rendimiento de los datos. Para esta medición, usaremos KNN con los hiperparámetros por defecto, y modificaremos el escalado usando varios formatos (_Standard, MinMax, Robust_) y también el tratado de datos vacios o imputación de datos, usando otras métricas (_Media, Mediana_, al tratarse de atributos numéricos). Por último, en todos los casos usaremos la metodología de evaluación de modelos __3-Fold con crossvalidation__. Con todo esto buscamos obtener el Escaler-Imputer que de el mejor rendimiento de la partición de entrenamiento.\n",
        "\n",
        "- __Creación de Modelos y Ajuste de hyperparametro HPO:__\n",
        "\n",
        "  Una vez hecho lo anterior, comenzamos la búsqueda del mejor modelo; se construirán una serie de modelos basandonos en las metodologías aprendidas en clase (KNN, Árboles de Decisión, Modelos Lineales y SVMs) mientras realizamos el __ajuste de hiperparámetros__ (HPO), y elegiremos el modelo que mejor se ajuste a los datos, procurando evitar cualquier data-leakage y overfitting/underfitting.\n",
        "\n",
        "- __Evaluación del modelo final de entrenamiento:__\n",
        "\n",
        "  Cuando hayamos encontrado la mejor alternativa usaremos el conjunto de test anteriormente apartado para obtener una __estimación y rendimiento a futuro del modelo__. Esto es lo que se conoce como la evaluación del modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2. Entrenamiento y evaluación del modelo final"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2Zt93s-ERjL"
      },
      "source": [
        "Los pasos anteriores en conjunto nos dirigen al entrenamiento del modelo final, el cual se entrena con el dataset completo (entrenamiento + test) y evaluaremos realizando predicciones con un conjunto de datos de competición aparte.\n",
        "\n",
        "Toda esta implementación se realiza en el [segundo Jupyter Notebook](enlacealsiguiente) a entregar con la práctica."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkRHkombEjzd"
      },
      "source": [
        "## 4. Métodos Básicos: KNN y TREES; imputación, escalado y ajuste de hiperparámetros"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5UuMqsDCIB4"
      },
      "source": [
        "Como hemos establecido anteriormente, el primer paso es realizar el escalado/imputación de los datos, de manera que sea el modelo el que se ajuste a éstos. Para ello, es necesario la importación de las siguientes librerías de SkLearn:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 213,
      "metadata": {
        "id": "9nLBgZ27RFQP"
      },
      "outputs": [],
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder, RobustScaler, StandardScaler\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.1. División de los datos: particiones de entrenamiento y test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eM2JYZHfCIB4"
      },
      "source": [
        "Para establecer la división de los datos haremos uso de la función `train_test_split()`,  en la que especificaremos la metodología __Holdout__ que divide las particiones de entrenamiento y test en una proporción (2/3, 1/3).\n",
        "\n",
        "También inicializaremos el atributo _random_state_ con un valor predefinido, ya que esto garantiza que se mantenga el mismo conjunto de datos de partición de entrenamiento y de test en todas las ejecuciones. En el caso de inicializarlo a ` None`, estaríamos dejando al azar el entrenamiento del modelo, ya que hay algunas métricas como en KNN que no se basan en estadísticas globales de los datos, y esto puede variar el resultado cada vez que ejecutemos el código.\n",
        "\n",
        "El valor elegido será `random_state=42` (número aleatorio).\n",
        "\n",
        "Una vez especificado esto, se procede a la partición de los datos."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 214,
      "metadata": {
        "id": "e0jHHodYKV6h"
      },
      "outputs": [],
      "source": [
        "X = datos.drop(\"Attrition\", axis=1)\n",
        "y = datos[\"Attrition\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2. Escalado e imputación de la partición de entrenamiento; creación del preprocesador"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tzbu8uVQRQn3"
      },
      "source": [
        "Una vez divididos los datos, buscaremos el modelo que mejor se adapte a la partición de entrenamiento según el tipo de imputación y escalado de datos. Para los escaladores usaremos los tres escaladores estudiados en clase para KNN: __MinMax (to 0-1 range), Estandarización y RobustScaler__; mientras que para los imputadores usaremos los especificados en el enunciado: __la media y la mediana__ de las variables de la misma instancia (imputación univariante).\n",
        "\n",
        "También usaremos como clasificador KNN y como métrica para la puntuación de cada imputer/scaler __balanced accuracy__:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 215,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jo8pt_MWFQuR",
        "outputId": "41f7946c-a878-4913-b278-c066237fa716"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Scaler: StandardScaler(), Imputer: SimpleImputer(), Score: 0.5761237407807159\n",
            "Scaler: StandardScaler(), Imputer: SimpleImputer(strategy='median'), Score: 0.5764301133297356\n",
            "Scaler: MinMaxScaler(), Imputer: SimpleImputer(), Score: 0.573666014570966\n",
            "Scaler: MinMaxScaler(), Imputer: SimpleImputer(strategy='median'), Score: 0.573666014570966\n",
            "Scaler: RobustScaler(), Imputer: SimpleImputer(), Score: 0.5883600917431192\n",
            "Scaler: RobustScaler(), Imputer: SimpleImputer(strategy='median'), Score: 0.5834665632307968\n",
            "\n",
            "Mejor Scaler: RobustScaler(), Mejor Imputer: SimpleImputer(), Mejor Score: 0.5883600917431192\n"
          ]
        }
      ],
      "source": [
        "# Lista de escaladores e imputadores\n",
        "Scalers = [StandardScaler(), MinMaxScaler(), RobustScaler()]\n",
        "Imputers = [SimpleImputer(strategy=\"mean\"), SimpleImputer(strategy=\"median\")]\n",
        "\n",
        "# Variables para almacenar el mejor modelo y su puntuación\n",
        "mejor_scaler = None\n",
        "mejor_imputer = None\n",
        "mejor_score = 0\n",
        "\n",
        "# Defiinimos el transformer para columnas categóricas\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "  (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "  ])\n",
        "\n",
        "# Iteramos sobre los escaladores\n",
        "for scaler in Scalers:\n",
        "\n",
        "  # Iteramos sobre los imputadores\n",
        "  for imputer in Imputers:\n",
        "\n",
        "    # Pipeline para las columnas numéricas\n",
        "    numerical_transformer = Pipeline(steps=[\n",
        "      (\"imputer\", imputer), (\"scaler\", scaler)\n",
        "      ])\n",
        "\n",
        "    # Preprocesador combinado\n",
        "    preprocessor = ColumnTransformer(transformers=[\n",
        "      (\"num\", numerical_transformer, numericas),\n",
        "      (\"cat\", categorical_transformer, categoricas)\n",
        "      ])\n",
        "\n",
        "    # Pipeline completo con clasificador (se utiliza KNN para clasificar)\n",
        "    pipeline = Pipeline(steps=[\n",
        "      (\"preprocessor\", preprocessor),\n",
        "      (\"classifier\", KNeighborsClassifier())\n",
        "      ])\n",
        "\n",
        "    # Evaluación del modelo con 3-fold cross-validation (se utiliza balanced_accuracy como métrica)\n",
        "    score = cross_val_score(pipeline, X_train, y_train,\n",
        "                            cv=3, scoring=\"balanced_accuracy\").mean()\n",
        "\n",
        "    # Comparamos con el mejor modelo\n",
        "    if score > mejor_score:\n",
        "      mejor_score = score\n",
        "      mejor_scaler = scaler\n",
        "      mejor_imputer = imputer\n",
        "\n",
        "    # Imprimimos los resultados de cada combinación\n",
        "    print(f\"Scaler: {scaler}, Imputer: {imputer}, Score: {score}\")\n",
        "\n",
        "# Obtenemos el mejor scaler/imputer y su score\n",
        "print(f\"\\nMejor Scaler: {mejor_scaler}, Mejor Imputer: {mejor_imputer}, Mejor Score: {mejor_score}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xvPTlpAsQhw9"
      },
      "source": [
        "Observando los datos podemos concluir que el mejor método de escalado es `RobustScaler()`, el cual es particularmente útil cuando existen valores atípicos en los datos, ya que transforma los atributos usando la mediana y el rango intercuartílico; mientras que el mejor método de imputación (univariante) es `SimpleImputer(strategy=\"mean\")`, el cual reemplaza los valores faltantes con la media de cada atributo. Esta estrategia es muy común y sobretodo adecuada cuando los datos son aproximadamente simétricos.\n",
        "\n",
        "Estos valores quedan reservados en las variables locales `mejor_scaler` y `mejor_imputer`\n",
        "\n",
        "A continuación, definiremos un __preprocesador__, que usaremos en los distintos modelos a lo largo del cuaderno, con los valores obtenidos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 216,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Definimos el codificador de variables categóricas\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "       (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "       ])\n",
        "\n",
        "# Definimos el mejor escalador e imputador obtenidos anteriormente\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "       (\"imputer\", mejor_imputer),\n",
        "       (\"scaler\", mejor_scaler)\n",
        "       ])\n",
        "\n",
        "# Preprocesador combinado para columnas numéricas y categóricas\n",
        "preprocesador = ColumnTransformer(transformers=[\n",
        "       (\"num\", numerical_transformer, numericas),\n",
        "       (\"cat\", categorical_transformer, categoricas)\n",
        "       ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Este preprocesador queda almacenado en la variable `preprocesador`.\n",
        "\n",
        "Finalmente, utilizaremos un diccionario que almacenará el modelo de clasificación junto con los resultados obtenidos en puntuación y tiempo de ejecución. Este diccionario se declarará en la variable `resultados`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 217,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Creamos un diccionario para almacenar los resultados de los modelos\n",
        "resultados = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3. Modelos iniciales con hiperparámetros por defecto"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Una vez tenemos los métodos de escalado y de imputación seleccionados, junto con el preprocesador de los datos preparado, podemos pasar a la siguiente fase. Antes de realizar el ajuste de hiperparámetros, primeramente buscaremos los modelos de KNN y Árboles de Decisión con los hiperparámetros por defecto:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 218,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKWVKWvkCIB9",
        "outputId": "69986c4b-2a68-4c35-85b3-8b866c751ba2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modelo KNeighborsClassifier\n",
            "Puntuación de validación cruzada: 0.5883600917431192\n",
            "Tiempo de ejecución: 0.2721383571624756 segundos\n",
            "\n",
            "Modelo DecisionTreeClassifier\n",
            "Puntuación de validación cruzada: 0.7739504632128081\n",
            "Tiempo de ejecución: 0.33917880058288574 segundos\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Definimos los clasificadores KNN y DecisionTreeClassifier\n",
        "clasificadores = [KNeighborsClassifier(), DecisionTreeClassifier(random_state=42)]\n",
        "\n",
        "# Iteramos sobre los clasificadores\n",
        "for clasificador in clasificadores:\n",
        "    \n",
        "    # Configuramos el clasificador para que use pesos balanceados si es un árbol de decisión\n",
        "    if isinstance(clasificador, DecisionTreeClassifier):\n",
        "           clasificador.set_params(class_weight=\"balanced\")\n",
        "\n",
        "    # Pipeline completo con clasificador\n",
        "    pipeline = Pipeline(steps=[\n",
        "           (\"preprocessor\", preprocesador),\n",
        "           (\"classifier\", clasificador)\n",
        "           ])\n",
        "\n",
        "    # Medimos el tiempo de entrenamiento del modelo\n",
        "    start_time = time.time()\n",
        "    scores = cross_val_score(pipeline, X_train, y_train, cv=3, scoring='balanced_accuracy')\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Imprimimos los resultados\n",
        "    print(\"Modelo\", clasificador.__class__.__name__)\n",
        "    print(\"Puntuación de validación cruzada:\", scores.mean())\n",
        "    print(\"Tiempo de ejecución:\", end_time - start_time, \"segundos\\n\")\n",
        "\n",
        "    # Almacenamos los resultados en el diccionario\n",
        "    resultados[clasificador.__class__.__name__] = {\n",
        "       \"modelo\": clasificador,\n",
        "       \"puntuacion\": scores.mean(),\n",
        "       \"tiempo_ejecucion\": end_time - start_time,\n",
        "       \"hiperparametros\": None\n",
        "       }\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.4. Ajuste de hiperparámetros (HPO)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A continuación, usaremos la metodología `GridSearch()` para encontrar el mejor ajuste de hiperparámetros para cada uno de los dos métodos.\n",
        "\n",
        "Consideraremos los siguientes hiperparámetros para el modelo __KNN__:\n",
        "- __Grado de clasificación (_k_)__: representa el número de datos de entrenamiento más cercanos a la instancia a evaluar que se consideran para determinar la predicción del modelo\n",
        "- __Métricas de distancia entre instancias vecinas__: distancia euclídea, distancia de Manhattan y distancia de Minkowski\n",
        "\n",
        "Por otro lado, los hiperparámetros a medir para los __arboles de decisión__ son los siguientes:\n",
        "- __Profundidad máxima del árbol (_max_depth_)__: es el máximo de profundidad que se permite para la creación del árbol. Esto influye en las instancias agrupadas en cada nodo hoja.\n",
        "- __Número mínimo de instancias (_min_samples_split_)__: se condiciona el número mínimo de instancias para poder realizar una patición de un nodo intermedio.\n",
        "- __Criterio de impureza__: se varía el cálculo para determinar qué atributos influyen más en la clasificación (_entropía_ e _impureza de Gini_).\n",
        "\n",
        "Podríamos añadir muchos más hiperparámetros que harían este proceso mucho más efectivo, pero también buscamos reducir el tiempo de ejecución. Por lo tanto, nos serviremos de los hiperparámetros fundamentales que estimen un modelo con un mayor rendimiento.\n",
        "\n",
        "Además, para evitar que se ejecute durante más tiempo, repartiremos el trabajo entre todos los kernels de la máquina con `n_jobs=-1`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 219,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57Bqmm-NWzKQ",
        "outputId": "bfc4fcbd-ebaf-4102-b747-c2abed8bf6f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modelo KNeighborsClassifier con HPO\n",
            "Mejores parámetros: {'classifier__metric': 'euclidean', 'classifier__n_neighbors': 3}\n",
            "Mejor puntuación: 0.6595936769203093\n",
            "Tiempo de ejecución: 7.504579782485962 segundos\n",
            "\n",
            "Modelo DecisionTreeClassifier con HPO\n",
            "Mejores parámetros: {'classifier__criterion': 'gini', 'classifier__max_depth': 15, 'classifier__min_samples_split': 5}\n",
            "Mejor puntuación: 0.782812218924267\n",
            "Tiempo de ejecución: 1.7572901248931885 segundos\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Iteramos sobre los clasificadores\n",
        "for clasificador in clasificadores:\n",
        "\n",
        "    # Definimos una pipeline con el preprocesador y el clasificador\n",
        "    pipeline = Pipeline(steps=[\n",
        "           (\"preprocessor\", preprocesador),\n",
        "           (\"classifier\", clasificador)\n",
        "           ])\n",
        "\n",
        "    # Definimos la rejilla de hiperparámetros para cada clasificador\n",
        "    if isinstance(clasificador, KNeighborsClassifier):\n",
        "            param_grid = {\n",
        "                'classifier__n_neighbors': [3, 5, 7, 9, 11],\n",
        "                'classifier__metric': ['euclidean', 'manhattan', 'minkowski']\n",
        "            }\n",
        "    elif isinstance(clasificador, DecisionTreeClassifier):\n",
        "            # Configuramos el clasificador para que use pesos balanceados si es un árbol de decisión\n",
        "            clasificador.set_params(class_weight=\"balanced\")\n",
        "            param_grid = {\n",
        "                'classifier__max_depth': [5, 10, 15, None],\n",
        "                'classifier__min_samples_split': [2, 5, 10],\n",
        "                'classifier__criterion': ['gini', 'entropy'],\n",
        "            }\n",
        "\n",
        "    # Entrenamos el modelo con GridSearchCV para encontrar los mejores hiperparámetros\n",
        "    grid_search = GridSearchCV(pipeline, param_grid, cv=3, n_jobs=-1, scoring='balanced_accuracy')\n",
        "\n",
        "    # Medimos el tiempo del entrenamiento del modelo\n",
        "    start_time = time.time()\n",
        "    grid_search.fit(X_train, y_train)\n",
        "    end_time = time.time()\n",
        "\n",
        "    # Mostrar los mejores hiperparámetros\n",
        "    print(\"Modelo\", clasificador.__class__.__name__, \"con HPO\")\n",
        "    print(\"Mejores parámetros:\", grid_search.best_params_)\n",
        "    print(\"Mejor puntuación:\", grid_search.best_score_)\n",
        "    print(\"Tiempo de ejecución:\", end_time - start_time, \"segundos\\n\")\n",
        "    \n",
        "    # Guardamos el mejor modelo en la instancia del diccionario con HPO\n",
        "    resultados[clasificador.__class__.__name__+\"_HPO\"] = {\n",
        "        \"modelo\": clasificador,\n",
        "        \"puntuacion\": grid_search.best_score_,\n",
        "        \"tiempo_ejecucion\": end_time - start_time,\n",
        "        \"hiperparametros\": grid_search.best_params_\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.5. Modelo Dummy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSjLo59iopY6"
      },
      "source": [
        "El __modelo Dummy__ es el modelo que clasifica todas las instancias a la clase mayoritaria, lo cual es inefectivo para nuestro problema, ya que causará un modelo con muy baja tasa de acierto.\n",
        "\n",
        "Sin embargo, saber las métricas de este modelo puede ayudarnos a comprobar que los modelos creados anteriormente sean efectivos. Los modelos obtenidos anteriormente se considerarán como válidos si superan la tasa de acierto de este modelo.\n",
        "\n",
        "En este caso, no se realiza ajuste de hiperparámetros, ya que la creación de este modelo es meramente orientativa:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 220,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jovm0KWqL8K",
        "outputId": "adcf33fc-cdd3-4f22-f5f9-d58b4e6aedf4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modelo DummyClassifier\n",
            "Mejor puntuación: 0.5\n",
            "Tiempo de ejecución: 0.0339052677154541 segundos\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Definimos el clasificador DummyClassifier\n",
        "dummy_clf = DummyClassifier(strategy='most_frequent')\n",
        "\n",
        "# Medimos el tiempo del entrenamiento del modelo\n",
        "start_time = time.time()\n",
        "score = cross_val_score(dummy_clf, X_train, y_train, cv=3, scoring='balanced_accuracy').mean()\n",
        "end_time = time.time()\n",
        "\n",
        "# Mostramos los resultadosd\n",
        "print(\"Modelo DummyClassifier\")\n",
        "print(\"Mejor puntuación:\", score)\n",
        "print(\"Tiempo de ejecución:\", end_time - start_time, \"segundos\\n\")\n",
        "\n",
        "# Guardamos el modelo en el diccionario\n",
        "resultados[dummy_clf.__class__.__name__] = {\n",
        "    \"modelo\": dummy_clf,\n",
        "    \"puntuacion\": score,\n",
        "    \"tiempo_ejecucion\": end_time - start_time,\n",
        "    \"hiperparametros\": None\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Como es obvio, el modelo Dummy obtendrá una __tasa de aciertos del 50%__, lo cual es inferior a la puntuación obtenida en los modelos anteriores. Esto nos confirma que los modelos son correctos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "### 4.6. Comparativa de modelos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "De forma sencilla, podemos crear un DataFrame con los resultados del proceso de búsqueda. Podemos acceder al objeto `RandomSearchCV` empleando el parámetro `named_steps` de la pipeline.\n",
        "\n",
        "A continuación, podemos hacer un poco de limpieza del dataframe para aumentar la claridad de las columnas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUfX_kb9WGRB"
      },
      "source": [
        "## 5. Avanzados: Modelos lineales y SVMs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A continuación, una vez evaluados los modelos simples (KNN y árboles), podemos pasar a la siguiente parte del entrenamiento. Avanzamos a modelos más complejos para nuestro dataset: __modelos lineales de regresión y máquinas de vectores de soporte (SVMs)__.\n",
        "\n",
        "Continuaremos con nuestra metodología de creación de modelos con los parámetros por omisión antes de pasar al ajuste de hiperparámetros, usando los valores de escalado e imputación obtenidos en el apartado anterior (y, por supuesto, midiendo el tiempo de ejeución y su puntuación obtenida).\n",
        "\n",
        "A continuación, establecemos todas las librerías que se van a utilizar en este apartado:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 221,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.1. Modelos lineales de clasificación (Regresión Logística)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para empezar, mediremos nuestro modelo usando un modelo de regresión logística, el cual es un modelo lineal adaptado a problemas de clasificación. Para ello, usaremos el modelo `LogisticRegression()`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 222,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modelo LogisticRegression\n",
            "Mejor puntuación: 0.7392769607843137\n",
            "Tiempo de ejecución: 0.27158045768737793 segundos\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Definimos el clasificador LogisticRegression\n",
        "logistic_clf = LogisticRegression(random_state=42)\n",
        "\n",
        "# Balanceamos los pesos\n",
        "logistic_clf.set_params(class_weight=\"balanced\")\n",
        "\n",
        "# Definimos la pipeline con el preprocesador y el clasificador\n",
        "pipeline = Pipeline(steps=[\n",
        "           (\"preprocessor\", preprocesador),\n",
        "           (\"classifier\", logistic_clf)\n",
        "           ])\n",
        "\n",
        "# Medimos el tiempo del entrenamiento del modelo\n",
        "start_time = time.time()\n",
        "score = cross_val_score(pipeline, X_train, y_train, cv=3, scoring='balanced_accuracy').mean()\n",
        "end_time = time.time()\n",
        "\n",
        "# Mostramos los resultados\n",
        "print(\"Modelo LogisticRegression\")\n",
        "print(\"Mejor puntuación:\", score)\n",
        "print(\"Tiempo de ejecución:\", end_time - start_time, \"segundos\\n\")\n",
        "\n",
        "# Guardamos el modelo en el diccionario\n",
        "resultados[logistic_clf.__class__.__name__] = {\n",
        "    \"modelo\": logistic_clf,\n",
        "    \"puntuacion\": score,\n",
        "    \"tiempo_ejecucion\": end_time - start_time,\n",
        "    \"hiperparametros\": None\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A continuación, mostramos el mismo tipo de modelo aplicando la __regularización Lasso (L1)__, la cual utiliza una función de penalización en valor absoluto de los valores absolutos de los coeficientes, lo que puede provocar que algunos se vean reducidos exactamente a cero. Si se da el caso, significará que algunas variables no contribuyen a la predicción.\n",
        "\n",
        "Para ello, usaremos el mismo objeto `LogisticRegression()`, añadiendo como atributos la penalización Lasso `penalty='l1'`, y el solver `'liblinear'`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 223,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modelo LogisticRegression con reg. Lasso\n",
            "Mejor puntuación: 0.7365218564490016\n",
            "Tiempo de ejecución: 0.20186805725097656 segundos\n"
          ]
        }
      ],
      "source": [
        "# Definimos el clasificador LogisticRegression con regularización Lasso (L1)\n",
        "# Usamos el solver 'liblinear' para la penalización L1\n",
        "logistic_Lasso_clf = LogisticRegression(random_state=42, penalty='l1', solver='liblinear')\n",
        "\n",
        "# Balanceamos los pesos\n",
        "logistic_Lasso_clf.set_params(class_weight=\"balanced\")\n",
        "\n",
        "# Definimos el pipeline con el preprocesador y el clasificador\n",
        "pipeline = Pipeline(steps=[\n",
        "           (\"preprocessor\", preprocesador),\n",
        "           (\"classifier\", logistic_Lasso_clf)\n",
        "           ])\n",
        "\n",
        "# Medimos el tiempo del entrenamiento del modelo\n",
        "start_time = time.time()\n",
        "score = cross_val_score(pipeline, X_train, y_train, cv=3, scoring='balanced_accuracy').mean()\n",
        "end_time = time.time()\n",
        "\n",
        "# Mostramos los resultados\n",
        "print(\"Modelo LogisticRegression con reg. Lasso\")\n",
        "print(\"Mejor puntuación:\", score)\n",
        "print(\"Tiempo de ejecución:\", end_time - start_time, \"segundos\")\n",
        "\n",
        "# Guardamos el modelo en el diccionario\n",
        "resultados[logistic_Lasso_clf.__class__.__name__+\"_Lasso\"] = {\n",
        "    \"modelo\": logistic_Lasso_clf,\n",
        "    \"puntuacion\": score,\n",
        "    \"tiempo_ejecucion\": end_time - start_time,\n",
        "    \"hiperparametros\": None\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Podemos apreciar que el modelo lineal se ve afectado negativamente con la regularización implicada. Esto puede deberse a que se realiza una __regularización excesiva de los datos__, convirtiendo el modelo a una versión más simplista que no utiliza información relevante que el modelo anterior sí usa. Es decir, el modelo de clasificación lineal realiza un mejor desempeño sin regularización Lasso que con ella.\n",
        "\n",
        "Seguidamente, nos disponemos a realiza el __ajuste de hiperparámetros__ de los dos modelos creados anteriormente (modelos lineales con y sin regularización Lasso). Ajustaremos los siguientes __hiperparámetros__:\n",
        "\n",
        "- __Función de coste (_C_)__: controla la regularización aplicada al modelo, y su principal objetivo es prevenir el sobreajuste de los datos de entrenamiento.\n",
        "- __Número máximo de iteraciones__: controla el número máximo de iteraciones que el algoritmo de optimización (__descenso de gradiente__) realizará para encontrar los coeficientes óptimos del modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 224,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modelo LogisticRegression con HPO\n",
            "Mejor puntuación: 0.7417251304191401\n",
            "Mejores parámetros: {'classifier__C': 100, 'classifier__max_iter': 100}\n",
            "Tiempo de ejecución: 0.946984052658081 segundos\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Definimos el clasificador LogisticRegression\n",
        "logistic_clf = LogisticRegression(random_state=42)\n",
        "\n",
        "# Balanceamos los pesos\n",
        "logistic_clf.set_params(class_weight=\"balanced\")\n",
        "\n",
        "# Definimos el pipeline con el preprocesador y el clasificador\n",
        "pipeline = Pipeline(steps=[\n",
        "           (\"preprocessor\", preprocesador),\n",
        "           (\"classifier\", logistic_clf)\n",
        "           ])\n",
        "\n",
        "param_grid = {\n",
        "    'classifier__C': [0.01, 0.1, 1, 10, 100],\n",
        "    'classifier__max_iter': [100, 200, 300]\n",
        "}\n",
        "\n",
        "# Hacemos búsqueda con rejilla para buscar los mejores hiperparámetros\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=3, n_jobs=-1, scoring='balanced_accuracy')\n",
        "\n",
        "# Medimos el tiempo del entrenamiento del modelo\n",
        "start_time = time.time()\n",
        "grid_search.fit(X_train, y_train)\n",
        "end_time = time.time()\n",
        "\n",
        "# Mostramos los resultados\n",
        "print(\"Modelo LogisticRegression con HPO\")\n",
        "print(\"Mejor puntuación:\", grid_search.best_score_)\n",
        "print(\"Mejores parámetros:\", grid_search.best_params_)\n",
        "print(\"Tiempo de ejecución:\", end_time - start_time, \"segundos\\n\")\n",
        "\n",
        "# Guardamos el modelo en el diccionario\n",
        "resultados[logistic_clf.__class__.__name__+\"_HPO\"] = {\n",
        "    \"modelo\": grid_search.best_estimator_,\n",
        "    \"puntuacion\": grid_search.best_score_,\n",
        "    \"tiempo_ejecucion\": end_time - start_time,\n",
        "    \"hiperparametros\": grid_search.best_params_\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Continuamos con el ajuste de hiperparámetros del modelo aplicando regularización L1:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 225,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modelo LogisticRegression con reg. Lasso y HPO\n",
            "Mejor puntuación: 0.7432541824069077\n",
            "Mejores parámetros: {'classifier__C': 100, 'classifier__max_iter': 100}\n",
            "Tiempo de ejecución: 3.345431089401245 segundos\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Definimos el clasificador LogisticRegression\n",
        "logistic_Lasso_clf = LogisticRegression(random_state=42, penalty='l1', solver='liblinear')\n",
        "\n",
        "# Balanceamos los pesos\n",
        "logistic_Lasso_clf.set_params(class_weight=\"balanced\")\n",
        "\n",
        "pipeline = Pipeline(steps=[\n",
        "           (\"preprocessor\", preprocesador),\n",
        "           (\"classifier\", logistic_Lasso_clf)\n",
        "           ])\n",
        "\n",
        "param_grid = {\n",
        "    'classifier__C': [0.01, 0.1, 1, 10, 100],\n",
        "    'classifier__max_iter': [100, 200, 300]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=3, n_jobs=-1, scoring='balanced_accuracy')\n",
        "\n",
        "# Medimos el tiempo del entrenamiento del modelo\n",
        "start_time = time.time()\n",
        "grid_search.fit(X_train, y_train)\n",
        "end_time = time.time()\n",
        "\n",
        "# Mostramos los resultados\n",
        "print(\"Modelo LogisticRegression con reg. Lasso y HPO\")\n",
        "print(\"Mejor puntuación:\", grid_search.best_score_)\n",
        "print(\"Mejores parámetros:\", grid_search.best_params_)\n",
        "print(\"Tiempo de ejecución:\", end_time - start_time, \"segundos\\n\")\n",
        "\n",
        "# Guardamos el modelo en el diccionario\n",
        "resultados[logistic_Lasso_clf.__class__.__name__+\"_Lasso_HPO\"] = {\n",
        "    \"modelo\": grid_search.best_estimator_,\n",
        "    \"puntuacion\": grid_search.best_score_,\n",
        "    \"tiempo_ejecucion\": end_time - start_time,\n",
        "    \"hiperparametros\": grid_search.best_params_\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A diferencia de lo obtenido anteriormente, esta vez la regularización Lasso ha resultado ser eficiente; se ha obtenido una puntuación mayor en el modelo lineal cuando se le aplica la regularización. Esto puede deberse a que, con los hiperparámetros obtenidos, sin dicha regularización, el modelo tiende al __sobreajuste de datos__ (overfitting); la regularización se encarga de reducirlo, lo que causa una mejor generalización del modelo."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.2. Máquinas de Vectores de Soporte (SVMs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Las máquinas de vectores de soporte son un tipo de modelos basados en funciones matemáticas utilizadas tanto para clasificación como para regresión; y establecen fronteras entre las distintas clases en el espacio de instancias.\n",
        "\n",
        "Para crear un modelo de esta tipología adaptado a nuestro problema, usaremos el objeto `SVC()` de la librería `sklearn.svm`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 226,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modelo SVM\n",
            "Mejor puntuación: 0.7989982460874258\n",
            "Tiempo de ejecución: 0.5895633697509766 segundos\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Definimos el clasificador SVM\n",
        "svm_clf = SVC(random_state=42)\n",
        "\n",
        "# Balanceamos los pesos\n",
        "svm_clf.set_params(class_weight=\"balanced\")\n",
        "\n",
        "# Definimos el pipeline con el preprocesador y el clasificador\n",
        "pipeline = Pipeline(steps=[\n",
        "           (\"preprocessor\", preprocesador),\n",
        "           (\"classifier\", svm_clf)\n",
        "           ])\n",
        "\n",
        "# Medimos el tiempo del entrenamiento del modelo\n",
        "start_time = time.time()\n",
        "score = cross_val_score(pipeline, X_train, y_train, cv=3, scoring='balanced_accuracy').mean()\n",
        "end_time = time.time()\n",
        "\n",
        "# Mostramos los resultados\n",
        "print(\"Modelo SVM\")\n",
        "print(\"Mejor puntuación:\", score)\n",
        "print(\"Tiempo de ejecución:\", end_time - start_time, \"segundos\\n\")\n",
        "\n",
        "# Guardamos el modelo en el diccionario\n",
        "resultados[svm_clf.__class__.__name__] = {\n",
        "    \"modelo\": svm_clf,\n",
        "    \"puntuacion\": score,\n",
        "    \"tiempo_ejecucion\": end_time - start_time,\n",
        "    \"hiperparametros\": None\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A continuación, realizaremos el __ajuste de hiperparámetros__ del modelo basado en SVMs. Se ajustarán los siguientes hiperparámetros:\n",
        "\n",
        "- __Coste (_C_)__: controla el peso que se le da a la correcta clasificación de los datos de entrenamiento versus la maximización del margen; también permite controlar el sobreaprendizaje. Un valor alto de _C_ enfoca el modelo a la minimización de variables de holgura, mientras que un valor bajo hace que se le de relevancia al vector de pesos.\n",
        "- __Kernel__: es una función de similitud que permite determinar cuánto se parecen entre sí el vector de soporte con la instancia a clasificar. También define fronteras de decisión no lineales sin realizar explícitamente la transformación a un espacio de mayor dimensión."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 227,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Modelo SVM con HPO\n",
            "Mejores parámetros: {'classifier__C': 10, 'classifier__kernel': 'rbf'}\n",
            "Mejor puntuación: 0.8314714876776398\n",
            "Tiempo de ejecución: 1.9058620929718018 segundos\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Definimos el clasificador SVM\n",
        "svm_clf = SVC(random_state=42)\n",
        "\n",
        "# Balanceamos los pesos\n",
        "svm_clf.set_params(class_weight=\"balanced\")\n",
        "\n",
        "# Definimos el pipeline con el preprocesador y el clasificador\n",
        "pipeline = Pipeline(steps=[\n",
        "           (\"preprocessor\", preprocesador),\n",
        "           (\"classifier\", svm_clf)\n",
        "           ])\n",
        "\n",
        "# Definimos la rejilla de hiperparámetros para el clasificador SVM\n",
        "param_grid = {\n",
        "    'classifier__C': [0.01, 0.1, 1, 10],\n",
        "    'classifier__kernel': ['rbf', 'poly']\n",
        "}\n",
        "\n",
        "# Hacemos búsqueda con rejilla para buscar los mejores hiperparámetros\n",
        "grid_search = GridSearchCV(pipeline, param_grid, cv=3, n_jobs=-1, scoring='balanced_accuracy')\n",
        "\n",
        "# Medimos el tiempo del entrenamiento del modelo\n",
        "start_time = time.time()\n",
        "grid_search.fit(X_train, y_train)\n",
        "end_time = time.time()\n",
        "\n",
        "# Mostramos los resultados\n",
        "print(\"Modelo SVM con HPO\")\n",
        "print(\"Mejores parámetros:\", grid_search.best_params_)\n",
        "print(\"Mejor puntuación:\", grid_search.best_score_)\n",
        "print(\"Tiempo de ejecución:\", end_time - start_time, \"segundos\\n\")\n",
        "\n",
        "# Guardamos el modelo en el diccionario\n",
        "resultados[svm_clf.__class__.__name__+\"_HPO\"] = {\n",
        "    \"modelo\": grid_search.best_estimator_,\n",
        "    \"puntuacion\": grid_search.best_score_,\n",
        "    \"tiempo_ejecucion\": end_time - start_time,\n",
        "    \"hiperparametros\": grid_search.best_params_\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.3. ¿Es posible extraer de alguna técnica qué atributos son más relevantes? ¿Cuáles son?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Comparación de resultados y evaluación del modelo de entrenamiento"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Una vez hemos probado todos los modelos vamos a ponerlos en conjunto, comparar sus resultados y vamos a sacar conclusiones sobre cuál es el mejor clasificador e hiperparámetros a utilizar. Posteriormente, con los mejores resultados obtenidos, crearemos el modelo a partir de la partición de entrenamiento, y mediante _cross validation_ __obtendremos una estimación pesimista del rendimiento a futuro del modelo usando la partición del test__. Por último, entrenaremos el modelo con todo el dataset completo (entrenamiento + test) y lo usaremos para obtener predicciones de un conjunto de datos de competición en el siguiente Jupyter Notebook."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.1. Comparación de resultados"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A continuación, añadimos un fragmento de código que imprime lo que se ha ido almacenando en el diccionario de resultados conforme añadíamos los modelos creados y evaluados para obtener el clasificador y combinación de hiperparámetros que mejor generalizaba la partición de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 228,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Resultados de los modelos:\n",
            "\n",
            "Modelo: KNeighborsClassifier\n",
            "Puntuación: 0.5883600917431192\n",
            "Tiempo de ejecución: 0.2721383571624756 segundos\n",
            "\n",
            "Modelo: DecisionTreeClassifier\n",
            "Puntuación: 0.7739504632128081\n",
            "Tiempo de ejecución: 0.33917880058288574 segundos\n",
            "\n",
            "Modelo: KNeighborsClassifier_HPO\n",
            "Puntuación: 0.6595936769203093\n",
            "Tiempo de ejecución: 7.504579782485962 segundos\n",
            "Hiperparámetros: {'classifier__metric': 'euclidean', 'classifier__n_neighbors': 3}\n",
            "\n",
            "Modelo: DecisionTreeClassifier_HPO\n",
            "Puntuación: 0.782812218924267\n",
            "Tiempo de ejecución: 1.7572901248931885 segundos\n",
            "Hiperparámetros: {'classifier__criterion': 'gini', 'classifier__max_depth': 15, 'classifier__min_samples_split': 5}\n",
            "\n",
            "Modelo: DummyClassifier\n",
            "Puntuación: 0.5\n",
            "Tiempo de ejecución: 0.0339052677154541 segundos\n",
            "\n",
            "Modelo: LogisticRegression\n",
            "Puntuación: 0.7392769607843137\n",
            "Tiempo de ejecución: 0.27158045768737793 segundos\n",
            "\n",
            "Modelo: LogisticRegression_Lasso\n",
            "Puntuación: 0.7365218564490016\n",
            "Tiempo de ejecución: 0.20186805725097656 segundos\n",
            "\n",
            "Modelo: LogisticRegression_HPO\n",
            "Puntuación: 0.7417251304191401\n",
            "Tiempo de ejecución: 0.946984052658081 segundos\n",
            "Hiperparámetros: {'classifier__C': 100, 'classifier__max_iter': 100}\n",
            "\n",
            "Modelo: LogisticRegression_Lasso_HPO\n",
            "Puntuación: 0.7432541824069077\n",
            "Tiempo de ejecución: 3.345431089401245 segundos\n",
            "Hiperparámetros: {'classifier__C': 100, 'classifier__max_iter': 100}\n",
            "\n",
            "Modelo: SVC\n",
            "Puntuación: 0.7989982460874258\n",
            "Tiempo de ejecución: 0.5895633697509766 segundos\n",
            "\n",
            "Modelo: SVC_HPO\n",
            "Puntuación: 0.8314714876776398\n",
            "Tiempo de ejecución: 1.9058620929718018 segundos\n",
            "Hiperparámetros: {'classifier__C': 10, 'classifier__kernel': 'rbf'}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"Resultados de los modelos:\\n\")\n",
        "for nombre, resultado in resultados.items():\n",
        "    print(f\"Modelo: {nombre}\")\n",
        "    print(f\"Puntuación: {resultado['puntuacion']}\")\n",
        "    print(f\"Tiempo de ejecución: {resultado['tiempo_ejecucion']} segundos\")\n",
        "    if resultado['hiperparametros']:\n",
        "        print(f\"Hiperparámetros: {resultado['hiperparametros']}\")\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para ver esto mejor, usaremos un `DataFrame()` de la librería Pandas:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>puntuacion</th>\n",
              "      <th>tiempo_ejecucion</th>\n",
              "      <th>hiperparametros</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>DummyClassifier</th>\n",
              "      <td>0.5</td>\n",
              "      <td>0.033905</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KNeighborsClassifier</th>\n",
              "      <td>0.58836</td>\n",
              "      <td>0.272138</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>KNeighborsClassifier_HPO</th>\n",
              "      <td>0.659594</td>\n",
              "      <td>7.50458</td>\n",
              "      <td>{'classifier__metric': 'euclidean', 'classifier__n_neighbors': 3}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LogisticRegression_Lasso</th>\n",
              "      <td>0.736522</td>\n",
              "      <td>0.201868</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LogisticRegression</th>\n",
              "      <td>0.739277</td>\n",
              "      <td>0.27158</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LogisticRegression_HPO</th>\n",
              "      <td>0.741725</td>\n",
              "      <td>0.946984</td>\n",
              "      <td>{'classifier__C': 100, 'classifier__max_iter': 100}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>LogisticRegression_Lasso_HPO</th>\n",
              "      <td>0.743254</td>\n",
              "      <td>3.345431</td>\n",
              "      <td>{'classifier__C': 100, 'classifier__max_iter': 100}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DecisionTreeClassifier</th>\n",
              "      <td>0.77395</td>\n",
              "      <td>0.339179</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>DecisionTreeClassifier_HPO</th>\n",
              "      <td>0.782812</td>\n",
              "      <td>1.75729</td>\n",
              "      <td>{'classifier__criterion': 'gini', 'classifier__max_depth': 15, 'classifier__min_samples_split': 5}</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVC</th>\n",
              "      <td>0.798998</td>\n",
              "      <td>0.589563</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>SVC_HPO</th>\n",
              "      <td>0.831471</td>\n",
              "      <td>1.905862</td>\n",
              "      <td>{'classifier__C': 10, 'classifier__kernel': 'rbf'}</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                             puntuacion tiempo_ejecucion  \\\n",
              "DummyClassifier                     0.5         0.033905   \n",
              "KNeighborsClassifier            0.58836         0.272138   \n",
              "KNeighborsClassifier_HPO       0.659594          7.50458   \n",
              "LogisticRegression_Lasso       0.736522         0.201868   \n",
              "LogisticRegression             0.739277          0.27158   \n",
              "LogisticRegression_HPO         0.741725         0.946984   \n",
              "LogisticRegression_Lasso_HPO   0.743254         3.345431   \n",
              "DecisionTreeClassifier          0.77395         0.339179   \n",
              "DecisionTreeClassifier_HPO     0.782812          1.75729   \n",
              "SVC                            0.798998         0.589563   \n",
              "SVC_HPO                        0.831471         1.905862   \n",
              "\n",
              "                                                                                                                 hiperparametros  \n",
              "DummyClassifier                                                                                                             None  \n",
              "KNeighborsClassifier                                                                                                        None  \n",
              "KNeighborsClassifier_HPO                                       {'classifier__metric': 'euclidean', 'classifier__n_neighbors': 3}  \n",
              "LogisticRegression_Lasso                                                                                                    None  \n",
              "LogisticRegression                                                                                                          None  \n",
              "LogisticRegression_HPO                                                       {'classifier__C': 100, 'classifier__max_iter': 100}  \n",
              "LogisticRegression_Lasso_HPO                                                 {'classifier__C': 100, 'classifier__max_iter': 100}  \n",
              "DecisionTreeClassifier                                                                                                      None  \n",
              "DecisionTreeClassifier_HPO    {'classifier__criterion': 'gini', 'classifier__max_depth': 15, 'classifier__min_samples_split': 5}  \n",
              "SVC                                                                                                                         None  \n",
              "SVC_HPO                                                                       {'classifier__C': 10, 'classifier__kernel': 'rbf'}  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from IPython.display import display\n",
        "\n",
        "# Configuramos pandas para mostrar todas las columnas\n",
        "pd.set_option('display.max_colwidth', None)\n",
        "\n",
        "# Convertimos el diccionario en un DataFrame\n",
        "results_df = pd.DataFrame(resultados)\n",
        "\n",
        "# Trasponemos el DataFrame para una mejor visualización, eliminamos la instancia del modelo\n",
        "results_df = results_df.T.drop(columns=[\"modelo\"])\n",
        "\n",
        "results_df = results_df.sort_values(by=\"puntuacion\", ascending=True)\n",
        "\n",
        "# Mostramos la tabla\n",
        "display(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Como podemos comprobar, el mejor clasificador obtenido es __SVM con ajuste de hiperparámetros__:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 230,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "El mejor modelo es: SVC_HPO con una puntuación de 0.8314714876776398 y tiempo de ejecución 1.9058620929718018.\n"
          ]
        }
      ],
      "source": [
        "mejor_puntuacion = 0\n",
        "mejor_modelo = None\n",
        "tiempo_ejecucion = None\n",
        "# Iteramos sobre los resultados para encontrar el mejor modelo\n",
        "for nombre, resultado in resultados.items():\n",
        "    if resultado['puntuacion'] > mejor_puntuacion:\n",
        "        mejor_puntuacion = resultado['puntuacion']\n",
        "        mejor_modelo = nombre\n",
        "        tiempo_ejecucion = resultado['tiempo_ejecucion']\n",
        "\n",
        "print(f\"El mejor modelo es: {mejor_modelo} con una puntuación de {mejor_puntuacion} y tiempo de ejecución {tiempo_ejecucion}.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.2. Estimación del rendimiento a futuro del modelo final"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.3. Entrenamiento del modelo final"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6.4. Obtención de predicciones (Notebook 2)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
